{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "02_rnn_optim.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXVQdchiRTeQ"
      },
      "source": [
        "# RNN: Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwZuL8_1RTeo"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# for printing the definition of custom functions\n",
        "import inspect\n",
        "\n",
        "# models\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor \n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "# pytorch\n",
        "from torch import nn, no_grad, save, load\n",
        "from torch import from_numpy, zeros\n",
        "from torch.optim import SGD\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# plots\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-dark')\n",
        "%matplotlib inline\n",
        "\n",
        "import pickle\n"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIyQNzzMRTet"
      },
      "source": [
        "models = []\n",
        "n_epochs = 500"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK6c-EVGSWSf",
        "outputId": "bedd5e14-9351-4261-dce0-ba1f8f32a882"
      },
      "source": [
        "wdir= os.getcwd()\n",
        "print(wdir)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfyNpVJKRTev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b98709-2a30-4c1c-ad85-feca6129cb55"
      },
      "source": [
        "database_dir = os.path.join(wdir, 'database.pickle')\n",
        "\n",
        "with open(database_dir,'rb') as f: \n",
        "    db = pickle.load(f)\n",
        "    \n",
        "database_training = db['database_training']\n",
        "database_validation = db['database_validation']\n",
        "database_test = db['database_test']\n",
        "\n",
        "database_training_sv = db['database_training_sv']\n",
        "database_validation_sv = db['database_validation_sv']\n",
        "database_test_sv = db['database_test_sv']\n",
        "\n",
        "database_training_sv_standard = db['database_training_sv_standard']\n",
        "database_validation_sv_standard = db['database_validation_sv_standard']\n",
        "database_test_sv_standard = db['database_test_sv_standard']\n",
        "\n",
        "database_scaler = db['database_scaler']"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doBvnD0WRTex"
      },
      "source": [
        "# =============================================================================\n",
        "# RNN start\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# # Prepare Data for RNN\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "# Combining orignal training and \n",
        "database_training = {}\n",
        "\n",
        "for country in database_training_sv_standard.keys():\n",
        "    df_to_add = database_training_sv_standard[country].append(database_validation_sv_standard[country])\n",
        "    df_to_add = df_to_add.reset_index()\n",
        "    del df_to_add['index']\n",
        "\n",
        "    database_training[country] = df_to_add\n",
        "\n",
        "\n",
        "N, dummy_dim = database_training['Germany'].shape\n",
        "dummy_dim -= 1\n",
        "\n",
        "time_steps = 10\n",
        "horizon = 1\n",
        "sequence_length = time_steps + horizon \n",
        "\n",
        "\n",
        "max_index = N - sequence_length + 1\n",
        "\n",
        "number_of_countries = len(database_training.keys())\n",
        "\n",
        "X = np.empty([0, sequence_length,dummy_dim])\n",
        "y = np.empty([0, sequence_length])\n",
        "\n",
        " \n",
        "\n",
        "for country in database_training.keys():\n",
        "    df_training_current = database_training[country]\n",
        "\n",
        "    X_current = np.empty([max_index, sequence_length,dummy_dim])\n",
        "    y_current = np.empty([max_index, sequence_length])\n",
        "\n",
        "    for i in range(max_index):\n",
        "\n",
        "        X_current[i] = df_training_current.iloc[i:i+sequence_length,1:].values\n",
        "        y_current[i] = df_training_current.iloc[i:i+sequence_length,0].values\n",
        "        \n",
        "    X = np.concatenate((X, X_current))\n",
        "    y = np.concatenate((y, y_current))\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "N, seq_len, dummy_dim = X.shape\n",
        "\n",
        "input_size=dummy_dim\n",
        "n_layers=1\n",
        "output_size=1\n",
        "test_size = 0.2\n",
        "batch_size = 25\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=123)\n",
        "\n",
        "\n",
        "X_train_T = from_numpy(X_train).float()\n",
        "y_train_T = from_numpy(y_train).float()\n",
        "X_val_T = from_numpy(X_val).float()\n",
        "y_val_T = from_numpy(y_val).float()\n",
        "\n",
        "train_ds = TensorDataset(X_train_T, y_train_T)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size)  \n",
        "\n",
        "valid_ds = TensorDataset(X_val_T, y_val_T)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)\n",
        "\n",
        "loss_func = nn.MSELoss()"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdl5am83w0Hm",
        "outputId": "316d67e6-07d3-4846-8581-d61b095bde4b"
      },
      "source": [
        "X_train_T.shape"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([720, 11, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T0TwXIkw4qT",
        "outputId": "112fb0cc-313d-40b6-9207-a90892603cfb"
      },
      "source": [
        "X_val_T.shape"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([180, 11, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKs4juorRTe0"
      },
      "source": [
        "# Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roKi92wARTe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa5c5c67-caa3-4a2d-cfcb-04c5a2d1a1e5"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.seq_len = seq_len\n",
        "        \n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        r_out, hidden = self.rnn(x, hidden)\n",
        "        r_out = self.fc(r_out)\n",
        "        \n",
        "        return r_out\n",
        "        \n",
        "    def initHidden(self):\n",
        "        return zeros(1, self.seq_len, self.hidden_dim)\n",
        "    \n",
        "name = 'RNN'\n",
        "hidden_dim=3\n",
        "lr = 0.03\n",
        "\n",
        "model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "optimizer = SGD(model.parameters(), lr = lr)  \n",
        "\n",
        "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
        "training_losses = np.empty(n_epochs)\n",
        "valid_losses = np.empty(n_epochs)\n",
        "\n",
        "# =============================================================================\n",
        "# # Training loop \n",
        "# =============================================================================\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    training_loss = 0\n",
        "    for X_batch, y_batch in train_dl:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(X_batch, hidden_0)\n",
        "        \n",
        "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
        "        \n",
        "        training_loss += loss.item()\n",
        "       \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "   \n",
        "\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    with no_grad():\n",
        "        for X_batch, y_batch in valid_dl:\n",
        "            y_pred = model(X_batch, hidden_0)\n",
        "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
        "            valid_loss += loss.item()\n",
        "    \n",
        "    \n",
        "    training_loss_epoch = training_loss \n",
        "    valid_loss_epoch = valid_loss \n",
        "    \n",
        "    training_losses[epoch] = training_loss_epoch\n",
        "    valid_losses[epoch] = valid_loss_epoch\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
        "              .format(epoch, training_loss_epoch, valid_loss_epoch))   \n",
        "        \n",
        "models.append( (name, training_losses, valid_losses))"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 165.2 valid loss: 27.19\n",
            "Epoch 100: train loss: 160.1 valid loss: 25.96\n",
            "Epoch 200: train loss: 158.4 valid loss: 25.14\n",
            "Epoch 300: train loss: 157.5 valid loss: 24.63\n",
            "Epoch 400: train loss: 157.0 valid loss: 24.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbO6kKe-RTe5"
      },
      "source": [
        "# Simple RNN Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCrX0rz0RTe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dfbb65f-5283-482e-eea0-786591e488ab"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.seq_len = seq_len\n",
        "        \n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        r_out, hidden = self.rnn(x, hidden)\n",
        "        r_out = self.fc(r_out)\n",
        "        \n",
        "        return r_out\n",
        "        \n",
        "    def initHidden(self):\n",
        "        return zeros(1, self.seq_len, self.hidden_dim)\n",
        "    \n",
        "name = 'RNN_Adam'\n",
        "hidden_dim=3\n",
        "lr = 1e-06\n",
        "\n",
        "model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        " \n",
        "\n",
        "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
        "training_losses = np.empty(n_epochs)\n",
        "valid_losses = np.empty(n_epochs)\n",
        "\n",
        "# =============================================================================\n",
        "# # Training loop \n",
        "# =============================================================================\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    training_loss = 0\n",
        "    for X_batch, y_batch in train_dl:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(X_batch, hidden_0)\n",
        "        \n",
        "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
        "        \n",
        "        training_loss += loss.item()\n",
        "       \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "   \n",
        "\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    with no_grad():\n",
        "        for X_batch, y_batch in valid_dl:\n",
        "            y_pred = model(X_batch, hidden_0)\n",
        "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
        "            valid_loss += loss.item()\n",
        "    \n",
        "    \n",
        "    training_loss_epoch = training_loss \n",
        "    valid_loss_epoch = valid_loss \n",
        "    \n",
        "    training_losses[epoch] = training_loss_epoch\n",
        "    valid_losses[epoch] = valid_loss_epoch\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
        "              .format(epoch, training_loss_epoch, valid_loss_epoch))   \n",
        "        \n",
        "models.append( (name, training_losses, valid_losses))\n"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 165.8 valid loss: 27.48\n",
            "Epoch 100: train loss: 165.7 valid loss: 27.47\n",
            "Epoch 200: train loss: 165.6 valid loss: 27.45\n",
            "Epoch 300: train loss: 165.5 valid loss: 27.44\n",
            "Epoch 400: train loss: 165.4 valid loss: 27.43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4CWfBEYRTe9"
      },
      "source": [
        "# RNN Large"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRwqJOa5RTe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4ff25e-0698-4a73-b9fd-8653971bba74"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.seq_len = seq_len\n",
        "        \n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        r_out, hidden = self.rnn(x, hidden)\n",
        "        r_out = self.fc(r_out)\n",
        "        \n",
        "        return r_out\n",
        "        \n",
        "    def initHidden(self):\n",
        "        return zeros(1, self.seq_len, self.hidden_dim)\n",
        "    \n",
        "name = 'RNN_Large_Adam'\n",
        "hidden_dim=64\n",
        "lr = 1e-06\n",
        "\n",
        "model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        " \n",
        "\n",
        "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
        "training_losses = np.empty(n_epochs)\n",
        "valid_losses = np.empty(n_epochs)\n",
        "\n",
        "# =============================================================================\n",
        "# # Training loop \n",
        "# =============================================================================\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    training_loss = 0\n",
        "    for X_batch, y_batch in train_dl:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(X_batch, hidden_0)\n",
        "        \n",
        "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
        "        \n",
        "        training_loss += loss.item()\n",
        "       \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "   \n",
        "\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    with no_grad():\n",
        "        for X_batch, y_batch in valid_dl:\n",
        "            y_pred = model(X_batch, hidden_0)\n",
        "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
        "            valid_loss += loss.item()\n",
        "    \n",
        "    \n",
        "    training_loss_epoch = training_loss \n",
        "    valid_loss_epoch = valid_loss \n",
        "    \n",
        "    training_losses[epoch] = training_loss_epoch\n",
        "    valid_losses[epoch] = valid_loss_epoch\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
        "              .format(epoch, training_loss_epoch, valid_loss_epoch))   \n",
        "        \n",
        "models.append( (name, training_losses, valid_losses))\n"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 163.7 valid loss: 27.28\n",
            "Epoch 100: train loss: 163.3 valid loss: 27.21\n",
            "Epoch 200: train loss: 163.0 valid loss: 27.16\n",
            "Epoch 300: train loss: 162.9 valid loss: 27.12\n",
            "Epoch 400: train loss: 162.7 valid loss: 27.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weke4lJBRTfC"
      },
      "source": [
        "# Simple LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KUwqrDDRTfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb3cea2-0eb6-4d40-829a-bc57810e0a01"
      },
      "source": [
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
        "        super(LSTMNet, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.seq_len = seq_len\n",
        "               \n",
        "        \n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, state):\n",
        "        r_out, (hidden_out, state_out) = self.lstm1(x, (hidden, state))\n",
        "        r_out = self.fc(r_out)\n",
        "        \n",
        "        return r_out\n",
        "        \n",
        "    def initHidden(self):\n",
        "        return zeros(1, self.seq_len, self.hidden_dim)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "name = 'LSTM'\n",
        "hidden_dim=10\n",
        "lr = 0.03\n",
        "\n",
        "model = LSTMNet(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "optimizer = SGD(model.parameters(), lr = lr)  \n",
        "\n",
        "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
        "state_0 = zeros(1, seq_len, hidden_dim)\n",
        "training_losses = np.empty(n_epochs)\n",
        "valid_losses = np.empty(n_epochs)\n",
        "\n",
        "\n",
        "    \n",
        "# =============================================================================\n",
        "# # Training loop \n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    training_loss = 0\n",
        "    for X_batch, y_batch in train_dl:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(X_batch, hidden_0, state_0)\n",
        "        \n",
        "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
        "        \n",
        "        training_loss += loss.item()\n",
        "       \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "   \n",
        "\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    with no_grad():\n",
        "        for X_batch, y_batch in valid_dl:\n",
        "            y_pred = model(X_batch, hidden_0, state_0)\n",
        "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
        "            valid_loss += loss.item()\n",
        "    \n",
        "    \n",
        "    training_loss_epoch = training_loss \n",
        "    valid_loss_epoch = valid_loss \n",
        "    \n",
        "    training_losses[epoch] = training_loss_epoch\n",
        "    valid_losses[epoch] = valid_loss_epoch\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
        "              .format(epoch, training_loss_epoch, valid_loss_epoch))  \n",
        "        \n",
        "        \n",
        "models.append( (name, training_losses, valid_losses))\n",
        "    "
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 163.5 valid loss: 27.07\n",
            "Epoch 100: train loss: 155.2 valid loss: 25.24\n",
            "Epoch 200: train loss: 140.7 valid loss: 24.49\n",
            "Epoch 300: train loss: 112.0 valid loss: 23.16\n",
            "Epoch 400: train loss: 99.03 valid loss: 25.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54zh7RHxRTfF"
      },
      "source": [
        "# LSTM Adam Large"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgGYIfjHRTfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8126bcdb-8165-467f-e92d-2ee0cadf6160"
      },
      "source": [
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
        "        super(LSTMNet, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.seq_len = seq_len\n",
        "               \n",
        "        \n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, state):\n",
        "        r_out, (hidden_out, state_out) = self.lstm1(x, (hidden, state))\n",
        "        r_out = self.fc(r_out)\n",
        "        \n",
        "        return r_out\n",
        "        \n",
        "    def initHidden(self):\n",
        "        return zeros(1, self.seq_len, self.hidden_dim)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "name = 'LSTM_Large_Adam'\n",
        "hidden_dim=64\n",
        "lr = 1e-06\n",
        "\n",
        "model = LSTMNet(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
        "state_0 = zeros(1, seq_len, hidden_dim)\n",
        "training_losses = np.empty(n_epochs)\n",
        "valid_losses = np.empty(n_epochs)\n",
        "\n",
        "\n",
        "    \n",
        "# =============================================================================\n",
        "# # Training loop \n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    training_loss = 0\n",
        "    for X_batch, y_batch in train_dl:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(X_batch, hidden_0, state_0)\n",
        "        \n",
        "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
        "        \n",
        "        training_loss += loss.item()\n",
        "       \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "   \n",
        "\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    with no_grad():\n",
        "        for X_batch, y_batch in valid_dl:\n",
        "            y_pred = model(X_batch, hidden_0, state_0)\n",
        "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
        "            valid_loss += loss.item()\n",
        "    \n",
        "    \n",
        "    training_loss_epoch = training_loss \n",
        "    valid_loss_epoch = valid_loss \n",
        "    \n",
        "    training_losses[epoch] = training_loss_epoch\n",
        "    valid_losses[epoch] = valid_loss_epoch\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
        "              .format(epoch, training_loss_epoch, valid_loss_epoch))  \n",
        "        \n",
        "        \n",
        "models.append( (name, training_losses, valid_losses))\n",
        "    "
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 163.2 valid loss: 27.08\n",
            "Epoch 100: train loss: 163.1 valid loss: 27.07\n",
            "Epoch 200: train loss: 163.0 valid loss: 27.05\n",
            "Epoch 300: train loss: 162.9 valid loss: 27.04\n",
            "Epoch 400: train loss: 162.9 valid loss: 27.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_ZmtLDqRTfH"
      },
      "source": [
        "# Stacked LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4JlgZ02RTfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dacea8a3-1fb8-4636-fa7b-853c720c956f"
      },
      "source": [
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
        "        super(LSTMNet, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.seq_len = seq_len\n",
        "               \n",
        "        \n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_dim)\n",
        "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden_1, state_1, hidden_2, state_2):\n",
        "        r_out, (hidden_out, state_out) = self.lstm1(x, (hidden_1, state_1))      \n",
        "        r_out, (hidden_out, state_out) = self.lstm2(r_out, (hidden_2, state_2))\n",
        "        r_out = self.fc(r_out)\n",
        "        \n",
        "        return r_out\n",
        "        \n",
        "    def initHidden(self):\n",
        "        return zeros(1, self.seq_len, self.hidden_dim)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "name = 'LSTM_Stacked'\n",
        "hidden_dim=64\n",
        "lr = 0.05\n",
        "\n",
        "model = LSTMNet(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "optimizer = SGD(model.parameters(), lr = lr)  \n",
        "\n",
        "hidden_01 = zeros(1, seq_len, hidden_dim)\n",
        "state_01 = zeros(1, seq_len, hidden_dim)\n",
        "\n",
        "hidden_02 = zeros(1, seq_len, hidden_dim)\n",
        "state_02 = zeros(1, seq_len, hidden_dim)\n",
        "\n",
        "training_losses = np.empty(n_epochs)\n",
        "valid_losses = np.empty(n_epochs)\n",
        "\n",
        "\n",
        "    \n",
        "# =============================================================================\n",
        "# # Training loop \n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    training_loss = 0\n",
        "    for X_batch, y_batch in train_dl:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(X_batch, hidden_01, state_01, hidden_02, state_02)\n",
        "        \n",
        "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
        "        \n",
        "        training_loss += loss.item()\n",
        "       \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "   \n",
        "\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    with no_grad():\n",
        "        for X_batch, y_batch in valid_dl:\n",
        "            y_pred = model(X_batch, hidden_01, state_01, hidden_02, state_02)\n",
        "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
        "            valid_loss += loss.item()\n",
        "    \n",
        "    \n",
        "    training_loss_epoch = training_loss \n",
        "    valid_loss_epoch = valid_loss \n",
        "    \n",
        "    training_losses[epoch] = training_loss_epoch\n",
        "    valid_losses[epoch] = valid_loss_epoch\n",
        "    \n",
        "    if epoch % 25 == 0:\n",
        "        print('Epoch {}: train loss: {:.8} valid loss: {:.8}'\n",
        "              .format(epoch, training_loss_epoch, valid_loss_epoch))  \n",
        "        \n",
        "        \n",
        "models.append( (name, training_losses, valid_losses))\n",
        "    "
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 163.10186 valid loss: 27.083196\n",
            "Epoch 25: train loss: 161.73081 valid loss: 26.755206\n",
            "Epoch 50: train loss: 157.9535 valid loss: 25.523838\n",
            "Epoch 75: train loss: 152.95524 valid loss: 24.271127\n",
            "Epoch 100: train loss: 144.09151 valid loss: 24.517672\n",
            "Epoch 125: train loss: 155.15516 valid loss: 25.328774\n",
            "Epoch 150: train loss: 144.16084 valid loss: 24.374774\n",
            "Epoch 175: train loss: 96.410418 valid loss: 23.098993\n",
            "Epoch 200: train loss: 53.714845 valid loss: 27.135338\n",
            "Epoch 225: train loss: 37.248569 valid loss: 27.701581\n",
            "Epoch 250: train loss: 33.643367 valid loss: 27.007507\n",
            "Epoch 275: train loss: 26.990821 valid loss: 26.660213\n",
            "Epoch 300: train loss: 25.520219 valid loss: 26.504651\n",
            "Epoch 325: train loss: 23.020821 valid loss: 26.029367\n",
            "Epoch 350: train loss: 20.060436 valid loss: 25.88581\n",
            "Epoch 375: train loss: 18.392862 valid loss: 25.840431\n",
            "Epoch 400: train loss: 17.330164 valid loss: 25.633932\n",
            "Epoch 425: train loss: 16.349625 valid loss: 25.373252\n",
            "Epoch 450: train loss: 14.38269 valid loss: 25.325208\n",
            "Epoch 475: train loss: 13.295862 valid loss: 25.433544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWWAIlxkRTfJ"
      },
      "source": [
        "x = [i for i in range(n_epochs)]\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(2,1, figsize=(12,10))\n",
        "\n",
        "for model_ in models:\n",
        "    name = model_[0]\n",
        "    training_loss = model_[1] / 720\n",
        "    valid_loss =model_[2] /  180\n",
        "\n",
        "    \n",
        "    label = name \n",
        "    \n",
        "    ax[0].plot(x,  training_loss, label=label)\n",
        "    ax[1].plot(x,  valid_loss, label=label)\n",
        "    #ax[2].plot([i for i in range(n_epochs-1)],  valid_loss[1:] / valid_loss[:-1] * 100, label=label)\n",
        "\n",
        "\n",
        "#ax[2].set_xlabel('epoch') \n",
        "\n",
        "ax[0].set_ylabel('loss') \n",
        "ax[1].set_ylabel('loss')\n",
        "\n",
        "ax[0].set_title(\"training loss\")\n",
        "ax[1].set_title(\"validation loss\")\n",
        "#ax[2].set_title(\"validation loss change in %\")\n",
        "\n",
        "legend  = ax[0].legend(bbox_to_anchor=(1.05, 1))\n",
        "\n",
        "ax[0].grid()\n",
        "ax[1].grid()\n",
        "#ax[2].grid()\n",
        "\n",
        "\n",
        "\n",
        "save_dir = os.path.join(wdir, 'result_all_models.png')\n",
        "\n",
        "plt.savefig(save_dir, dpi = 500, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
        "plt.close()"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlUyz16-RTfK"
      },
      "source": [
        "# Serializing best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eD7cKuORTfK"
      },
      "source": [
        "\n",
        "# =============================================================================\n",
        "# # Serializing model \n",
        "# =============================================================================\n",
        "\n",
        "#wdir= r'C:/Users/hauer/Documents/Repositories/cfds_project'\n",
        "save_dir = os.path.join(wdir, 'pytorch_models')\n",
        "model_name = 'rnn.torch'\n",
        "\n",
        "if(not os.path.isdir(save_dir)):\n",
        "    os.mkdir(save_dir)\n",
        "    \n",
        "save(model.state_dict(), os.path.join(save_dir, model_name))\n",
        "\n",
        "#model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "#model.load_state_dict(load( os.path.join(save_dir, model_name)))"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMTAKfuqRTfL"
      },
      "source": [
        "# Using model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymbAwustRTfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db852cb6-5e00-4a94-c5ba-df369951a9af"
      },
      "source": [
        "country = 'Germany'\n",
        "\n",
        "df = database_training_sv_standard[country].append(database_validation_sv_standard[country])\n",
        "\n",
        "n_forecast_validation, _ = database_validation_sv_standard[country].shape\n",
        "\n",
        "X_eval = df.iloc[:,1:].values\n",
        "y_eval = df.iloc[:,0].values\n",
        "X_eval_T = from_numpy(X_eval).float()\n",
        "N, _ = X_eval_T.shape\n",
        "X_eval_T = X_eval_T.view([-1, N, dummy_dim])\n",
        "\n",
        "hidden_1 = zeros(1, N, hidden_dim)\n",
        "state_1 = zeros(1, N, hidden_dim)\n",
        "\n",
        "hidden_2 = zeros(1, N, hidden_dim)\n",
        "state_2 = zeros(1, N, hidden_dim)\n",
        "\n",
        "model.eval()\n",
        "with no_grad():\n",
        "    y_hat = model(X_eval_T, hidden_1, state_1, hidden_2, state_2)\n",
        "    \n",
        "y_hat =  y_hat.view(-1).numpy()\n",
        "y_forecast = y_hat[-n_forecast_validation:]\n",
        "y_forecast"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.25307703,  0.38865948,  0.8269038 ,  0.0450716 , -1.069978  ,\n",
              "        0.8227167 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa2e0_SVRTfM"
      },
      "source": [
        "# Comparing with the ground truth.\n",
        "\n",
        "First check right application of scaling. The unscaled data must equal the scaled data after appling the inverse_transform method from sklearn: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U37yjGxRTfN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "9a673375-a32c-4a75-e42e-163dabed281f"
      },
      "source": [
        "scaler = database_scaler[country]\n",
        "\n",
        "database_validation_sv[country]"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>ExchangeR</th>\n",
              "      <th>PPP</th>\n",
              "      <th>Current account balance</th>\n",
              "      <th>GHG</th>\n",
              "      <th>Inflation, average consumer prices</th>\n",
              "      <th>General government net lending/borrowing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2005</th>\n",
              "      <td>2.051359</td>\n",
              "      <td>0.547797</td>\n",
              "      <td>0.654957</td>\n",
              "      <td>1.852348</td>\n",
              "      <td>0.661859</td>\n",
              "      <td>1.051777</td>\n",
              "      <td>-0.058174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006</th>\n",
              "      <td>2.518101</td>\n",
              "      <td>0.503668</td>\n",
              "      <td>0.662903</td>\n",
              "      <td>1.845025</td>\n",
              "      <td>0.640522</td>\n",
              "      <td>1.167132</td>\n",
              "      <td>-1.246360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007</th>\n",
              "      <td>2.072474</td>\n",
              "      <td>0.513078</td>\n",
              "      <td>0.658295</td>\n",
              "      <td>1.786614</td>\n",
              "      <td>0.661971</td>\n",
              "      <td>1.140200</td>\n",
              "      <td>-6.907755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008</th>\n",
              "      <td>2.013436</td>\n",
              "      <td>0.583932</td>\n",
              "      <td>0.662904</td>\n",
              "      <td>1.818870</td>\n",
              "      <td>0.617975</td>\n",
              "      <td>0.706676</td>\n",
              "      <td>3.318150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009</th>\n",
              "      <td>0.234375</td>\n",
              "      <td>0.582607</td>\n",
              "      <td>0.665526</td>\n",
              "      <td>1.812187</td>\n",
              "      <td>0.690894</td>\n",
              "      <td>1.869612</td>\n",
              "      <td>0.607133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010</th>\n",
              "      <td>1.860920</td>\n",
              "      <td>0.525331</td>\n",
              "      <td>0.659129</td>\n",
              "      <td>1.827969</td>\n",
              "      <td>0.634447</td>\n",
              "      <td>1.428403</td>\n",
              "      <td>-0.435978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             y  ...  General government net lending/borrowing\n",
              "2005  2.051359  ...                                 -0.058174\n",
              "2006  2.518101  ...                                 -1.246360\n",
              "2007  2.072474  ...                                 -6.907755\n",
              "2008  2.013436  ...                                  3.318150\n",
              "2009  0.234375  ...                                  0.607133\n",
              "2010  1.860920  ...                                 -0.435978\n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owQBrqHdRTfO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "49d8d9ff-8c1a-469f-82e0-d115cd4354ed"
      },
      "source": [
        "pd.DataFrame(scaler.inverse_transform(database_validation_sv_standard[country]))"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.051359</td>\n",
              "      <td>0.547797</td>\n",
              "      <td>0.654957</td>\n",
              "      <td>1.852348</td>\n",
              "      <td>0.661859</td>\n",
              "      <td>1.051777</td>\n",
              "      <td>-0.058174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.518101</td>\n",
              "      <td>0.503668</td>\n",
              "      <td>0.662903</td>\n",
              "      <td>1.845025</td>\n",
              "      <td>0.640522</td>\n",
              "      <td>1.167132</td>\n",
              "      <td>-1.246360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.072474</td>\n",
              "      <td>0.513078</td>\n",
              "      <td>0.658295</td>\n",
              "      <td>1.786614</td>\n",
              "      <td>0.661971</td>\n",
              "      <td>1.140200</td>\n",
              "      <td>-6.907755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.013436</td>\n",
              "      <td>0.583932</td>\n",
              "      <td>0.662904</td>\n",
              "      <td>1.818870</td>\n",
              "      <td>0.617975</td>\n",
              "      <td>0.706676</td>\n",
              "      <td>3.318150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.234375</td>\n",
              "      <td>0.582607</td>\n",
              "      <td>0.665526</td>\n",
              "      <td>1.812187</td>\n",
              "      <td>0.690894</td>\n",
              "      <td>1.869612</td>\n",
              "      <td>0.607133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.860920</td>\n",
              "      <td>0.525331</td>\n",
              "      <td>0.659129</td>\n",
              "      <td>1.827969</td>\n",
              "      <td>0.634447</td>\n",
              "      <td>1.428403</td>\n",
              "      <td>-0.435978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6\n",
              "0  2.051359  0.547797  0.654957  1.852348  0.661859  1.051777 -0.058174\n",
              "1  2.518101  0.503668  0.662903  1.845025  0.640522  1.167132 -1.246360\n",
              "2  2.072474  0.513078  0.658295  1.786614  0.661971  1.140200 -6.907755\n",
              "3  2.013436  0.583932  0.662904  1.818870  0.617975  0.706676  3.318150\n",
              "4  0.234375  0.582607  0.665526  1.812187  0.690894  1.869612  0.607133\n",
              "5  1.860920  0.525331  0.659129  1.827969  0.634447  1.428403 -0.435978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKm6Uy3JRTfP"
      },
      "source": [
        "Transforming the output back to original scale: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UunUd6AqRTfQ"
      },
      "source": [
        "df_output = database_validation_sv_standard[country]"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uXAFqw8RTfQ"
      },
      "source": [
        "Overwriting the forecast to the dataframe in order to call the inverse_transform method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUAQ6-2KRTfR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "49af427d-1f0c-4f83-a075-a81e5edfa2eb"
      },
      "source": [
        "df_output.iloc[:,0] = y_forecast\n",
        "df_output"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.253077</td>\n",
              "      <td>0.031546</td>\n",
              "      <td>-1.811933</td>\n",
              "      <td>0.233201</td>\n",
              "      <td>0.977376</td>\n",
              "      <td>0.173565</td>\n",
              "      <td>-1.540170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.388659</td>\n",
              "      <td>-0.691070</td>\n",
              "      <td>-0.464783</td>\n",
              "      <td>0.229011</td>\n",
              "      <td>-0.824086</td>\n",
              "      <td>0.244783</td>\n",
              "      <td>-5.745871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.826904</td>\n",
              "      <td>-0.536981</td>\n",
              "      <td>-1.245999</td>\n",
              "      <td>0.195587</td>\n",
              "      <td>0.986829</td>\n",
              "      <td>0.228155</td>\n",
              "      <td>-25.784944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.045072</td>\n",
              "      <td>0.623240</td>\n",
              "      <td>-0.464502</td>\n",
              "      <td>0.214045</td>\n",
              "      <td>-2.727739</td>\n",
              "      <td>-0.039492</td>\n",
              "      <td>10.410665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.069978</td>\n",
              "      <td>0.601555</td>\n",
              "      <td>-0.020067</td>\n",
              "      <td>0.210220</td>\n",
              "      <td>3.428772</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.814749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.822717</td>\n",
              "      <td>-0.336342</td>\n",
              "      <td>-1.104656</td>\n",
              "      <td>0.219251</td>\n",
              "      <td>-1.337028</td>\n",
              "      <td>0.406086</td>\n",
              "      <td>-2.877446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5          6\n",
              "0  0.253077  0.031546 -1.811933  0.233201  0.977376  0.173565  -1.540170\n",
              "1  0.388659 -0.691070 -0.464783  0.229011 -0.824086  0.244783  -5.745871\n",
              "2  0.826904 -0.536981 -1.245999  0.195587  0.986829  0.228155 -25.784944\n",
              "3  0.045072  0.623240 -0.464502  0.214045 -2.727739 -0.039492  10.410665\n",
              "4 -1.069978  0.601555 -0.020067  0.210220  3.428772  0.678478   0.814749\n",
              "5  0.822717 -0.336342 -1.104656  0.219251 -1.337028  0.406086  -2.877446"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ywerWgyRTfS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "3406139a-8511-4384-fd50-278018a1c4d3"
      },
      "source": [
        "df_output = pd.DataFrame(scaler.inverse_transform(df_output))\n",
        "df_output"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.121983</td>\n",
              "      <td>0.547797</td>\n",
              "      <td>0.654957</td>\n",
              "      <td>1.852348</td>\n",
              "      <td>0.661859</td>\n",
              "      <td>1.051777</td>\n",
              "      <td>-0.058174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.365687</td>\n",
              "      <td>0.503668</td>\n",
              "      <td>0.662903</td>\n",
              "      <td>1.845025</td>\n",
              "      <td>0.640522</td>\n",
              "      <td>1.167132</td>\n",
              "      <td>-1.246360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.153413</td>\n",
              "      <td>0.513078</td>\n",
              "      <td>0.658295</td>\n",
              "      <td>1.786614</td>\n",
              "      <td>0.661971</td>\n",
              "      <td>1.140200</td>\n",
              "      <td>-6.907755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.748101</td>\n",
              "      <td>0.583932</td>\n",
              "      <td>0.662904</td>\n",
              "      <td>1.818870</td>\n",
              "      <td>0.617975</td>\n",
              "      <td>0.706676</td>\n",
              "      <td>3.318150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.256155</td>\n",
              "      <td>0.582607</td>\n",
              "      <td>0.665526</td>\n",
              "      <td>1.812187</td>\n",
              "      <td>0.690894</td>\n",
              "      <td>1.869612</td>\n",
              "      <td>0.607133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.145887</td>\n",
              "      <td>0.525331</td>\n",
              "      <td>0.659129</td>\n",
              "      <td>1.827969</td>\n",
              "      <td>0.634447</td>\n",
              "      <td>1.428403</td>\n",
              "      <td>-0.435978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6\n",
              "0  2.121983  0.547797  0.654957  1.852348  0.661859  1.051777 -0.058174\n",
              "1  2.365687  0.503668  0.662903  1.845025  0.640522  1.167132 -1.246360\n",
              "2  3.153413  0.513078  0.658295  1.786614  0.661971  1.140200 -6.907755\n",
              "3  1.748101  0.583932  0.662904  1.818870  0.617975  0.706676  3.318150\n",
              "4 -0.256155  0.582607  0.665526  1.812187  0.690894  1.869612  0.607133\n",
              "5  3.145887  0.525331  0.659129  1.827969  0.634447  1.428403 -0.435978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eHRHz_RTfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7e2963-1a12-41cf-8982-9772c948d49b"
      },
      "source": [
        "y_forecast = df_output.iloc[:,0].values\n",
        "y_forecast"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.12198256,  2.36568654,  3.15341306,  1.7481012 , -0.25615547,\n",
              "        3.14588691])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk7BWv3wRTfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116d38b1-b68c-4b72-9bdb-114e7db5e6c6"
      },
      "source": [
        "database_validation_sv[country].iloc[:,0].values"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.05135894, 2.51810131, 2.07247393, 2.01343609, 0.23437483,\n",
              "       1.86092044])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    }
  ]
}