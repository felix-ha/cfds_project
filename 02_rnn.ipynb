{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for printing the definition of custom functions\n",
    "import inspect\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "# pytorch\n",
    "from torch import nn, no_grad, save, load\n",
    "from torch import from_numpy, zeros\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-dark')\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_dir = os.path.join(r'C:/Users/hauer/Documents/Repositories/cfds_project', 'database.pickle')\n",
    "\n",
    "with open(database_dir,'rb') as f: \n",
    "    db = pickle.load(f)\n",
    "    \n",
    "database_training = db['database_training']\n",
    "database_validation = db['database_validation']\n",
    "database_test = db['database_test']\n",
    "\n",
    "database_training_sv = db['database_training_sv']\n",
    "database_validation_sv = db['database_validation_sv']\n",
    "database_test_sv = db['database_test_sv']\n",
    "\n",
    "database_training_sv_standard = db['database_training_sv_standard']\n",
    "database_validation_sv_standard = db['database_validation_sv_standard']\n",
    "database_test_sv_standard = db['database_test_sv_standard']\n",
    "\n",
    "database_scaler = db['database_scaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RNN start\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# # Prepare Data for RNN\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "N, dummy_dim = database_training_sv_standard['Germany'].shape\n",
    "dummy_dim -= 1\n",
    "\n",
    "time_steps = 16\n",
    "horizon = 1\n",
    "sequence_length = time_steps + horizon \n",
    "\n",
    "\n",
    "max_index = N - sequence_length + 1\n",
    "\n",
    "number_of_countries = len(database_training_sv_standard.keys())\n",
    "\n",
    "X = np.empty([0, sequence_length,dummy_dim])\n",
    "y = np.empty([0, sequence_length])\n",
    "\n",
    " \n",
    "\n",
    "for country in database_training.keys():\n",
    "    df_training_current = database_training_sv_standard[country]\n",
    "\n",
    "    X_current = np.empty([max_index, sequence_length,dummy_dim])\n",
    "    y_current = np.empty([max_index, sequence_length])\n",
    "\n",
    "    for i in range(max_index):\n",
    "\n",
    "        X_current[i] = df_training_current.iloc[i:i+sequence_length,1:].values\n",
    "        y_current[i] = df_training_current.iloc[i:i+sequence_length,0].values\n",
    "        \n",
    "    X = np.concatenate((X, X_current))\n",
    "    y = np.concatenate((y, y_current))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "N, seq_len, dummy_dim = X.shape\n",
    "\n",
    "input_size=dummy_dim\n",
    "n_layers=1\n",
    "output_size=1\n",
    "test_size = 0.20\n",
    "batch_size = 25\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=123)\n",
    "\n",
    "\n",
    "X_train_T = from_numpy(X_train).float()\n",
    "y_train_T = from_numpy(y_train).float()\n",
    "X_val_T = from_numpy(X_val).float()\n",
    "y_val_T = from_numpy(y_val).float()\n",
    "\n",
    "train_ds = TensorDataset(X_train_T, y_train_T)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)  \n",
    "\n",
    "valid_ds = TensorDataset(X_val_T, y_val_T)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)\n",
    "\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 14.36 valid loss: 1.831\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "    \n",
    "name = 'RNN'\n",
    "hidden_dim=3\n",
    "lr = 0.03\n",
    "\n",
    "model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = SGD(model.parameters(), lr = lr)  \n",
    "\n",
    "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_0)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_0)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))   \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 17.42 valid loss: 2.618\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "    \n",
    "name = 'RNN_Adam'\n",
    "hidden_dim=3\n",
    "lr = 1e-06\n",
    "\n",
    "model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    " \n",
    "\n",
    "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_0)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_0)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))   \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 11.98 valid loss: 1.771\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "    \n",
    "name = 'RNN_Large_Adam'\n",
    "hidden_dim=64\n",
    "lr = 1e-06\n",
    "\n",
    "model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    " \n",
    "\n",
    "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_0)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_0)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))   \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 12.24 valid loss: 1.765\n"
     ]
    }
   ],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(LSTMNet, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "               \n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, state):\n",
    "        r_out, (hidden_out, state_out) = self.lstm1(x, (hidden, state))\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = 'LSTM'\n",
    "hidden_dim=10\n",
    "lr = 0.03\n",
    "\n",
    "model = LSTMNet(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = SGD(model.parameters(), lr = lr)  \n",
    "\n",
    "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
    "state_0 = zeros(1, seq_len, hidden_dim)\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "\n",
    "    \n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_0, state_0)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_0, state_0)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))  \n",
    "        \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Adam Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 11.85 valid loss: 1.747\n"
     ]
    }
   ],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(LSTMNet, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "               \n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, state):\n",
    "        r_out, (hidden_out, state_out) = self.lstm1(x, (hidden, state))\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = 'LSTM_Large_Adam'\n",
    "hidden_dim=64\n",
    "lr = 1e-06\n",
    "\n",
    "model = LSTMNet(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
    "state_0 = zeros(1, seq_len, hidden_dim)\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "\n",
    "    \n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_0, state_0)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_0, state_0)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))  \n",
    "        \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 11.04557 valid loss: 2.1442572\n",
      "Epoch 25: train loss: 11.026772 valid loss: 2.1446912\n",
      "Epoch 50: train loss: 11.017336 valid loss: 2.14389\n",
      "Epoch 75: train loss: 11.007253 valid loss: 2.1430744\n",
      "Epoch 100: train loss: 10.996872 valid loss: 2.1423137\n",
      "Epoch 125: train loss: 10.987199 valid loss: 2.1417197\n",
      "Epoch 150: train loss: 10.979161 valid loss: 2.1413414\n",
      "Epoch 175: train loss: 10.972848 valid loss: 2.1411036\n",
      "Epoch 200: train loss: 10.96762 valid loss: 2.1408895\n",
      "Epoch 225: train loss: 10.962751 valid loss: 2.1406311\n",
      "Epoch 250: train loss: 10.957751 valid loss: 2.1403171\n",
      "Epoch 275: train loss: 10.952332 valid loss: 2.1399575\n",
      "Epoch 300: train loss: 10.9463 valid loss: 2.139562\n",
      "Epoch 325: train loss: 10.939485 valid loss: 2.139133\n",
      "Epoch 350: train loss: 10.931713 valid loss: 2.1386716\n",
      "Epoch 375: train loss: 10.922791 valid loss: 2.138181\n",
      "Epoch 400: train loss: 10.912499 valid loss: 2.1376677\n",
      "Epoch 425: train loss: 10.900575 valid loss: 2.1371434\n",
      "Epoch 450: train loss: 10.886692 valid loss: 2.1366197\n",
      "Epoch 475: train loss: 10.870433 valid loss: 2.136099\n",
      "Epoch 500: train loss: 10.851269 valid loss: 2.1355648\n",
      "Epoch 525: train loss: 10.828569 valid loss: 2.1349674\n",
      "Epoch 550: train loss: 10.80165 valid loss: 2.1342179\n",
      "Epoch 575: train loss: 10.769848 valid loss: 2.1331805\n",
      "Epoch 600: train loss: 10.732548 valid loss: 2.1316824\n",
      "Epoch 625: train loss: 10.689176 valid loss: 2.1295495\n",
      "Epoch 650: train loss: 10.639204 valid loss: 2.12669\n",
      "Epoch 675: train loss: 10.582245 valid loss: 2.123206\n",
      "Epoch 700: train loss: 10.518182 valid loss: 2.1194901\n",
      "Epoch 725: train loss: 10.447324 valid loss: 2.1163055\n",
      "Epoch 750: train loss: 10.370677 valid loss: 2.1147329\n",
      "Epoch 775: train loss: 10.289956 valid loss: 2.1158134\n",
      "Epoch 800: train loss: 10.206566 valid loss: 2.119929\n",
      "Epoch 825: train loss: 10.120441 valid loss: 2.1264687\n",
      "Epoch 850: train loss: 10.029982 valid loss: 2.1340714\n",
      "Epoch 875: train loss: 9.9324092 valid loss: 2.1412214\n",
      "Epoch 900: train loss: 9.8242914 valid loss: 2.1466721\n",
      "Epoch 925: train loss: 9.7022641 valid loss: 2.1495638\n",
      "Epoch 950: train loss: 9.5629433 valid loss: 2.1494596\n",
      "Epoch 975: train loss: 9.4014679 valid loss: 2.1462405\n"
     ]
    }
   ],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(LSTMNet, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "               \n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_dim)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden_1, state_1, hidden_2, state_2):\n",
    "        r_out, (hidden_out, state_out) = self.lstm1(x, (hidden_1, state_1))      \n",
    "        r_out, (hidden_out, state_out) = self.lstm2(r_out, (hidden_2, state_2))\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = 'LSTM_Stacked'\n",
    "hidden_dim=64\n",
    "lr = 0.05\n",
    "\n",
    "model = LSTMNet(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = SGD(model.parameters(), lr = lr)  \n",
    "\n",
    "hidden_01 = zeros(1, seq_len, hidden_dim)\n",
    "state_01 = zeros(1, seq_len, hidden_dim)\n",
    "\n",
    "hidden_02 = zeros(1, seq_len, hidden_dim)\n",
    "state_02 = zeros(1, seq_len, hidden_dim)\n",
    "\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "\n",
    "    \n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_01, state_01, hidden_02, state_02)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_01, state_01, hidden_02, state_02)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 25 == 0:\n",
    "        print('Epoch {}: train loss: {:.8} valid loss: {:.8}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))  \n",
    "        \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvIAAAJICAYAAAADygBfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5hU5d3G8e+ZsmW2LyxL7/DQqwhYsZdoUOwaC7YYNSbWWNDEmPdVY9eYmFdUbNiDWFCxohIQaQoCjxRBOkvZ3nfn/WNmcelLmTk7O/fnuvbaM2fOmfmtP3e5z5nnPMcJBoOIiIiIiEhs8bhdgIiIiIiI7D0FeRERERGRGKQgLyIiIiISgxTkRURERERikIK8iIiIiEgMUpAXEREREYlBCvIiIi4yxkw2xjTfy30OMsa82YDt5hpjMve9um1e6wtjzJkH4rVEROTA8LldgIhInDtub3ew1s4E9hiqrbUD9qkiERGJCQryIiIuMcY8F1783BhzMvAV8A3QD7gdqAp/TwBaAM9ba+80xowA/mGt7WOMGQcUAn2BdsD3wEXW2mJjTBDIAU4BTgdqgW5AKXCxtXahMaYr8CyQDawFHOAla+243dR9GvBnQp/qFgE3WGtnGGN6AM8ASeHXGWut/eeu1u/XfzwREdHQGhERt1hrR4cXj7LWrgwvz7fW9gTeBm4kFLgPAoYBt+1iGM5g4ESgJ9AROGsn2xwJ/N5a24fQwcKt4fUvAq+E118HDN9dzeFQ/hRwhrW2P3AXMNEYkw7cDLxrrR0MnAwcYYzx7Ga9iIjsB/0hFRFpXL4CsNYGgVOBwcaYPwMPEzqbnbKTfT601lZYa6uAeYTOrm9vlrV2VXh5NpBtjMkCDgbGht9zIfDpHuo7GvjUWrssvM9nwAZCBxMTgFuMMf8BRgHXWWtrd7NeRET2g4K8iEjjUgxgjEkB5gCDCAXvmwkNtXF2sk9ZveXgXmxTHX5cf/uaPdTnDe9fnwfwW2vfIzR053VgIDDPGNN2V+v38D4iIrIHCvIiIu6qAfw7Wd8NSAfGWGvfBUYAiYSC9AFhrS0CpgKjAYwxnYBj2DGo1/cpcIIxpnN4n6MJjc3/xhgzHjjHWvsqcDWhsftddrX+QP0cIiLxShe7ioi46w1gijFm1HbrvwfeAxYZYyoIDZlZAHQFKg7g+18EPGOMuRpYDfxE6GLYnbLWLghv+x9jjC+87anW2gJjzD3AWGPMbwkdoEwAviQ09GZn60VEZD84weDuTryIiEhTZoy5A3jLWrvIGJNB6ADiJGvtApdLExGRPdAZeRGR+PYj8JoxppbQvwn3KcSLiMQGnZEXEREREYlButhVRERERCQGKciLiIiIiMQgBXkRERERkRjUJC52zcsrcmWgf2pqIsXFB3IWOGmM1Of4oD7HB/U5PqjP8cGNPufkpO3shnuu0Rn5/eDzHbD7skgjpj7HB/U5PqjP8UF9jg/qs4K8iIiIiEhMUpAXEREREYlBCvIiIiIiIjFIQV5EREREJAYpyIuIiIiIxCAFeRERERGRGKQgLyIiIiISgxTkRURERERiUJO4s6sb5q0p5J1PlvCnozrj8+p4SERERGRfzJ49k4kT3+Luu+/dum7VqpU89tiD1NTUUFNTgzE9ueqqa3n11Zf473+/pri4mM2bN9K+fUcAHnvsXxx55FBOO+0Mbrrptq2v8+ijD/D111/y5pvv7vL9p02byquvvoTjONTW1nLKKSM5/viTKCwsYPr0aRx//Il79fMYY9ZZa1vu5T49gKestSP2Zj8F+X1UVFHN29+tobKqmi7NUkhN9JKe5Cczue7LR0ayH79CvoiIiMSA939Yzzvz1x3Q1/x1n5b8qnfuXu/3738/yRlnnMOwYYcQDAa5/fab+eqrKZx//kWcf/5FzJ49k0mTJjJmzD1b98nIyGDu3NlUV1fj8/moqalh0aKFe3yvBx+8l3HjXiEtLY3S0hIuvvh8hgwZyk8/LWPq1Cl7HeSjSUF+Hw3vmMUxPVrw0aI8amo37HK7lARvvXDvJzPgJzMpFPS3WR/+Skvy4fU4UfxJRERERBqXli1b8cEH7xIIBOjVqw/33HMfXq93t/t4vT4GDBjMt99+w/DhhzJjxnQOOuhgPvzw/d3ul52dzRtvvMKIEcfQqVNnXn75DRISErj77jEsWbKYiRP/Q9++/XjiiUf49ttvPgEygeustf81xlwG/A7wAhOttX+pe11jzP8CGcC1wJnADUAN8LW19lZjTCvgZcAB9ukISkF+HzmOw1MXDGLLlhLKq2spKq+msKKagrIq8rf5qg59L61iU0klSzeWkF9WRXl17c5fF0hP2jHkZyTvOvynJnpxHIV/ERER2Xe/6p27T2fPI+GKK37H22+/yb///SRLly7hkEMO4/rrbyEtLW23+x133Im8++4Ehg8/lE8++ZCLL75sj0H+vvse5rXXxnP33XewZcsWRo4cxaWXXslFF13KxIlvMXLkKD79dDLXXns9w4YNPNYYcz4w2hizBLgV6AdUAA8ZY1IBjDEPArXW2muMMdnA3cBB1tpSY8yLxpjjgBOAV6y1TxtjziF0QLBXIhbkjTFDgfvrj/UxxjwCWGvtU9tt6wH+CfQn9B/icmvtEmPMMOAxoBqYbK29O1L17ivHcUj2e0n2e2mRltjg/cqrasgvq6KgLujv7ACgvIo1heUsWF/EltIqqmuDO30tr8chYyfhPzPZR2YgYacHAEk+j8K/iIiINEqzZ8/k7LPP5+yzz6e0tJQnn3yUcePG8vvfX7/b/fr168/DD99HQUE+BQUF5Oa22u32hYWFrFu3jquvvo6rr76OvLwN3HHHLRjTk0AgsHW75s1bMG7cWC6++JPngTSgEOgMzLfWloU3ux7AGJNLKNwvCa/vCuQAk4wxhPfvDPQGXgxvM5XGEuSNMbcAFwIl4cc5wAtAd+CBnexyGpBkrR0eDu8PASOBp4AzgGXA+8aYQdba2ZGoOdqS/F5a+r20TG/Y9sFgkNJw+K87y19QVsWW0m0PAArKqvhpU2loubyKXWR/En2eHcJ/ViB05j+r3uP6nwj4NORHREREouBf/3ocr9fDkCHDCAQCtGvXnoKCgj3u5zgOw4YdyoMP3sfhh4/Y4/ZVVZXcddet/POfY8nNbUmzZs1p1qwZCQkJeDweasNB6rHHHuCuu/7GU089ebEx5m6gI7AU6GGMSbTWVhhj3gT+AKwndLb9C2PMicAsYCVwnLW2yhhzCTAX6AEMB74DhuzlfyIgcmfklwKj+OUoIxX4C3DSLrY/DPgQwFo73RhzkDEmHUi01i4FMMZ8BBwDNIkgv7ccxyElwUdKgo82GQ3bpzYYpKi8epuz/DsO/Ql9rS0sZ0tZFcUVNbt8vfpDfurCfmZg2+X6zyX7ddZfRERE9mzGjG+47LILtz4eM+avPPnkozz11JP4/X5at27DTTfd2qDXOv74k7j88gu5+ebb97hts2bNuf76m7njjlvwer3U1tZwyCGHc/DBw8jL28CyZUt4/fXxHH/8Sdx6642sWvXzV8AqoLm1Ns8Ycz8wxRgTBN611q42xmCtDRpjLgU+AoYCD4e38wLLgdeBO4HXjDHnAj/txX+urZxgcBenbPeTMaYj8Kq1dli9dX8B1u1kaM1Y4C1r7Qfhxz8Dh4TXDQ2vuxTobK0ds/17lZVVBn2+3V8AEQler4eamp2PdY9VldW15JdVsqWkis2llWwpqWRzaSWbSyrZUloV/r7t410N+Un0ecgKJJCdkkBWwE92SgKZAT/pSaEz/GlJPjKS/KQn+0hP8pOe7Cc9KXSw4mlEZ/+bYp9lR+pzfFCf44P6HB/c6LPf7208AYXGc7FrIaHxQnU8O1mXBuTvbOfi4orIVbYbmZkB8vNLXXnvSEoAcpO85CYlQ3bybrcNBoOUVNZsHeKzJXxh79bluq/SSpZvLKGwvJriimp2d/jocSA10Uda3VdS6HtqopdAgo9AgpcUv5dAQvgrvJySUO/5hNB1CwdiBqCm2mfZlvocH9Tn+KA+x4e96fPEif/h448/3GH9VVddS58+/Rr8njk5u7/YNtoaS5CfCpwKvB4eIz/PWltojKk0xnQhNEb+BEJX/Eoj4jgOqYk+UhN9tMvafeivUxsMUlJRQ1FFNUXl1RRVhGb8Kd5uubAiFPqLyqv5qaSU4opqSitrKK2s2e2BQH2JPk844IcCf7LfS5LfQ7LfS6LPE37sJWnrsocknye0Lrw+J6uc6ooqkn11z4e+J+qCYRERkZgwcuQoRo4c5XYZB5yrQd4Y8wIwBpgAHGeM+S+hGRhHhze5itD8ml5Cs9Z840qhckB5HCd0lj3JF5pddS8Fg0HKq2spCYf60spqSiprKKsKPf5lfXi5qnrrcnl1LaWVNWwqqaK8uobyqlrKqmoor6qhZi9HmTlQ72DAszX4J/m9JNcL/Ml+L0m+0LqtBw7h5frr6paTdaAgIiIiDRCxMfLRlJdX5MoPoY/umpbqmlrKqmq3DfjVtfgS/eRtKaViu/XlVTW/bB9+XB5+XFZV9zi0XLfP3nDglwOB7UJ/3ScIOzsQ2NXzdZ9MpCT4SPA6OkjYjn6f44P6HB/U5/jgRp9zctIa1T+ejWVojYjrfF4PaV4Padv9WoT+UDRs2NDu1AaDVFaHQn1ZvU8C6pbLqrY9UNh+Xf3lwvBNxervv6uLjnfG63FISfDWG3bkIyUx/LjumoNE39ZrEVISw9sk/HI9Qt01CZqdSERExB0K8iJR4nGcrWPvsyLw+nWfKOxwABD+hKC08pchRtsPSyqprKGovJr1hRWUhNc19FoEjwOBBG/4guRfLlJOTapb9u5w8XL9xymJXjw6EBAREdlrCvIiTcTWTxSSDsyvdf1rEUoqqimtdw1CSeUvFx4Xh58vrqzZesHymsJyivNCy7u7NwGEhhClJO54IFA3PWlmso+M8E3JMpJCy5nh736v54D8rCIiIrFIQV5EdspxnPA4ey/NUxL2+XVqaoOUVtZQWFFFcXl4tqKKupD/y8xFxRXVFIVnM1pdUE7h+ioKyqup2M21BSkJ3q3hPiPJT0ayb5vv9e9anJ2SQKbuUCwiIk2IgryIRJTXs3+zFJVX1ZBfFgr1Bdt8/+VuxQXlVRSUVbOqoIyCstCBwc44QEY42DcL+EM3LAv4yQ4k0LZ5CkkOWx9nB/wk+aN/ozkREZGGUpAXkUYtye+lpd9Ly/SG71NdG6QwHO7zy6rYUlrJpro7E5dVsSl8Z+JF64vYXFpFSeXOh/8E/F6yAn5yUhNonpJITmpC+Ctxm+/JCvwiIuICBXkRaXJ8Hid8Vr1hQ4LKq2qo8ftYvq4wFPZLq9hUGvq+ubSSvOJKfswr5utlFTudRjQ10UtOSiLNUxNokZpA89REclISyElLJDc1gdz0JJoF/JrdR0REDigFeRGJe0l+L5mZyaTsYZ6eYDBISWUNecWV5BVXbP2+saSSDcWVbCyuYObKAjaWVFKz3XSgCV6H3LREWqYn0TItkVbpSeSmJ25dbpGWSKJPF++KiEjDKciLiDSQ4zikhmfX6dQssMvtaoNB8suqyCuqZF1RBeuLyllXWMHawtDy9BVb2FhcucNhQ7OUhHCwT6R1RjJtM5PCX8m0SE3Eqwt1RUSkHgV5EZEDzOP8MrTH5KbudJvK6lo2FFewrrCCdeGgX7f8Y14JXyzZtM1Nvvxeh1bp4WCfkUybzCTahMN+m4wkXZgrIhKHFORFRFyQ4PPQNjOZtpk7v2twTW2Q9UUVrMovY1VBOavzy1hdUM6q/HK+W124wwW6LVIT6JgdoEN2gI7ZyeHvAVqkJmhsvohIE6UgLyLSCHk9Dq0zkmidkcTB2z0XDAa3Tre5Kr+cVfllrMwvY8XmMiYtWL9NyA/4vXQIB/sOWcl0DAf89lnJJGhMvohITFOQFxGJMY7jkBnwkxnw06fVtvNyBoNBNpVUsnxzGcs3l7J8cykrNpfx3eoCPly4Yet2Xo9D+6xkujVPoWtOCl2ap9C1eQqt0hN1Bl9EJEYoyIuINCGO49A8NZHmqYkc1D5zm+fKqmr4eUsZyzeVsnRTCUvySpi3tpDJNm/rNikJXjo3S6FrToCuzVPpmhOge04qqYn650JEpLHRX2YRkTiR7PdiWqRiWmx7AW5xRTVLN5awdGMJSzaWsiSvmE/sRiZ8v27rNu2zkunRIpUeueGvFmmhu/WKiIhr9FdYRCTOpSb66N8mg/5tMrauCwaDbCiuZEleCYs2FLFofTHfrdn27H3bzCR6tEijZzjc98xVuBcRiSb9xRURkR04TugGVrlpiRzaOXvr+i2llSzaUMyi9cUsXF/MD+sK+eTHX8J9p2YB+rVKp2/rNPq0SqdTswAejbkXEYkIBXkREWmwrEACwztmM7zjL+E+v7SKRRuK+GFdEfPWFPHFko1MnB8alpOa6KVPy1Cw79s6nT4t03XWXkTkANFfUxER2S+ZAT/DOmYzLBzug8EgK7aUMW9NIfPWFjJvTRFjp/1MEHCALs1TGNwug0FtMxjYNoOsQIKr9YuIxCoFeREROaAcx9k6X/2pfVoCoQtqF6wr4vs1hcxZVcDEeet4bc4aIDQcZ1DbULAf1C6T5ikK9iIiDaEgLyIiEZea6OPgDlkc3CELgKqaWhauL2b2ynxmryrggwUbeOu7tUBohpwh7TMZ2iGLg9plaiiOiMgu6K+jiIhEnd/roV/rdPq1TueSoVBdG8SuL2L2qgJmrfwl2Hsc6N0ynWEdQ8G+d6t0fB5dPCsiAuAEg8GIvbgxZihwv7V2hDGmKzAOCALzgWustbX1tr0VODH8MBNoaa1taYy5AbgMqJsW4bfWWlv/ffLyiiL3Q+xGZmaA/PxSN95aokh9jg/qc+NSVVPL/LVFTF+xhW+Wb2Hh+iJqg6EbVg1pn8nBHbIY3jGLtpnJe/W66nN8UJ/jgxt9zslJa1RnEiJ2Rt4YcwtwIVASXvUwMMZa+4Ux5ilgJDChbntr7X3AfeF93wP+FH5qEHCRtXZWpGoVEZHGxe/1MDB8MezvDu1IQVkVM1fm882KLUxfvoUvlmwCoFN2gMM6Z3N4l2b0ba2z9SISXyI5tGYpMAp4Mfx4MDAlvPwBcDz1gnwdY8woYIu19qN6+91mjGkJvG+tvTeCNYuISCOUkeznmO45HNM9h2AwyMr8cv7702a+WrqJV2av5sWZq0hP8jG8YxaHd27G8E5ZpCf53S5bRCSiIhbkrbVvGWM61lvlWGvrhsAUARk77gXAbcB59R6/CjwJFAITjDGnWGvfq79DamoiPp/3wBS+F7xeD5mZgai/r0SX+hwf1OfYkpWVQr9Ozbjq6G4UlVfz9ZKNfP7jBr6weXy0KA+vx2Fw+0yO65XLCb1yaZURGoKjPscH9Tk+qM/Rvdi1tt5yGpC//QbGmF5AvrV2SfixAzxqrS0IP34fGAhsE+SLiysiVfNuaQxefFCf44P6HNuGt01neNt0/jSiCz+sK+LrZZv4cukm/mfSIv5n0iJ6t0zj6G7NGXlQOzI8blcrkabf5/jg0hj5qL7fnkQzyM8xxoyw1n4BnAR8vpNtjiU07KZOOjDfGNOT0Fj7o4FnI12oiIjEJq/H2TobztWHdWLF5lI+W7yRzxdv5ImvfuKJr36iW04Kx3RvztHdcujULL7P5olIbItmkL8ReNoYkwAsBN4EMMZMBk6x1lYCBvi4bgdrbYEx5nZCob8C+NRaOymKNYuISAzrkB1g9ND2jB7anjUF5UxfVcD736/lqakreGrqCjo1C3Bijxac0DOHNhl7NwOOiIjbIjr9ZLRo+kmJJPU5PqjP8aGuzxuKKvhiyUY+tnnMXV0IQN9W6ZzYswXHmeZkBXR32Vim3+f4oOknFeT3i/5QxAf1OT6oz/FhZ31eU1DO5EUb+GhRHks2luB1YGjHLE7o0YIRXZsTSIj+ZAqyf/T7HB8U5BXk94v+UMQH9Tk+qM/xYU99XpJXwoeLNvDRwg2sK6og0efh6G7N+XWflgxql4HHaVT/hssu6Pc5PijIR3eMvIiISKPWNSeFa3M6cfVhHZm3ppAPFm7go0Ub+GDhBlpnJHFK71xO6Z1Lq/Qkt0sVEdEZ+f2hI/74oD7HB/U5PuxLn8uravhiySbenb+OGT/n4wAHd8jk1N4tObJrM5L8GnrT2Oj3OT7ojLzOyIuIiOxWkt/LiT1bcGLPFqwpKOf9H9bz3g/rGDNpEWmJPk7u1YIz+rfWVJYiEnUK8iIiIg3UOiOJKw7pwGXD2zNrZT4T563jre/W8tqcNQxul8Gofq04qltz/F7ddUpEIk9BXkREZC95HIch7bMY0j6LG46q5J1565jw/VrueH8R2QE/I/u25PR+rTSWXkQiSmPk94PG4MUH9Tk+qM/xIZJ9rqkNMn35Ft78bg1Tl23GceCQTtmcO7ANB3fIxNGMN1Gj3+f4oDHyOiMvIiJyQHg9Dod2zubQztmsLSzn7e/X8va8dVz71jw6Nwtw3qA2nNizhS6OFZEDRmfk94OO+OOD+hwf1Of4EO0+V1bX8tGiDbwyezWL80rITPYzqn8rzurfiuapiVGrI97o9zk+6Iy8zsiLiIhETILPw6l9WnJK71xmrypg/KzVPDf9Z16YsZITeuRw3qC2mNxUt8sUkRilIC8iIhJhjuMwuF0mg9tlsnJLGa/NWc2789fz/oINDO2QycUHt+OgdhpHLyJ7R/NjiYiIRFG7rGRuOror7105lN8f3oklG0u5+o15XDJ+Lp8t3khtExjyKiLRoTPyIiIiLkhL8nHRwe04Z1AbJi1Yz4vfruRP7yygQ1YyFw1px0m9Wmg+ehHZLf2FEBERcVGiz8Pp/Vrxxugh3HtKT5L8Xu6Z/COnjZ3ByzNXUVZV43aJItJI6Yy8iIhII+D1OBxrcjime3NmrMhn3LcreXTKMp6fsZILh7TlzAGtSdbUlSJSj4K8iIhII+I4DkM7ZjG0YxbfrS5g7LSfefzLn3jx21UK9CKyDQ2tERERaaT6t8ngiTP7Mvbc/pgWqTz+5U+MfHoGL8xYSWmlhtyIxDsFeRERkUauLtA/c94ATG4qT3z1EyPHhgJ9ucbQi8QtBXkREZEY0a91Ok+cEQr0PcKB/vRnvuXNuWuorql1uzwRiTIFeRERkRhTF+j/75z+tMlI4v5Pl3DmczP5cOEGzUMvEkcU5EVERGLUwLYZPH1ufx45vTeBBC93TlrEb16czdfLNhFUoBdp8jRrjYiISAxzHIfDOjfjkE7ZTF6Ux1NTl3P9hB/o3zqdaw/vxIC2GW6XKCIREtEgb4wZCtxvrR1hjOkKjAOCwHzgGmttbb1tHWAVsDi8apq19jZjzKnAXUA18Ky19ulI1iwiIhKLPI7DiT1bcGz35kycv46x037mite+Y0TXZvz+iM60z0p2u0QROcAiNrTGGHMLMBZICq96GBhjrT0ccICR2+3SBZhtrR0R/rrNGOMHHgGOB44ErjTGtIxUzSIiIrHO5/VwRv/WTLhsCFcd2oFvVmzh7HEzeejzpRSUVbldnogcQJEcI78UGFXv8WBgSnj5A+DY7bYfDLQxxnxujJlkjDFAT2CJtXaLtbYS+Bo4PII1i4iINAlJfi+XDevAfy47mFN75/L6nNWc/sy3vDxzFZXVmuFGpCmI2NAaa+1bxpiO9VY51tq6K2+KgO0H7a0F7rXWvmGMOQx4CbgeKKi3zc72IzU1EZ8v+ne583o9ZGYGov6+El3qc3xQn+NDPPY5MzPAA2cP4PIjirj/I8ujU5bx1vdrufl4w4m9c3Ecx+0SD7h47HM8Up+je7Fr/cP/NCB/u+dnEhoHj7X2a2NMG0LBPW0P+1FcXHFgK22gzMwA+fmlrry3RI/6HB/U5/gQz33OTfLy8MheTFu+mcemLOO61+bSv3U61x/Vhd4t0/b8AjEknvscT9zoc05O4/pdieb0k3OMMSPCyycBX233/J+BPwIYY/oDPwMLgG7GmGxjTAJwBDAtOuWKiIg0PcM7ZvPyhYO547hurMwvY/TLc/jbRz+yubTS7dJEZC9F84z8jcDT4UC+EHgTwBgzGTgFuA94yRjzK0Jn5i+x1lYZY24APiJ00PGstXZ1FGsWERFpcrweh9P6teJYk8Mz03/mldmr+XRxHlcM78DZA1rj8+o2MyKxwGkKN4zIyyty5YfQR3fxQX2OD+pzfFCfd275plIe+mIp05dvoVOzADcd1YWDO2S5XdY+U5/jg0tDaxrVRSU65BYREYlzHZsFeHxUHx4c2ZvK6lqueXMet7yzgDUF5W6XJiK7oTu7ioiICI7jcGTXZgzrmMX4Wat4dvrP/PenzVw0pC0XH9yeRJ/O/Yk0NvqtFBERka0SfR5GD23PG6MP4oguzXh62s+c+/xMpi3f7HZpIrIdBXkRERHZQcv0JP73lJ48eWZfPI7DdW/N57Z3F5Ln0pTPIrIjBXkRERHZpYM7ZPHKRYP57SEd+HLpRs56biavzl5NdW3sT5YhEusU5EVERGS3EnweLh/egVcvPoi+rdN56POlXPLyHH5YW+h2aSJxTUFeREREGqRdVjKPj+rDvaf0ZFNJJaPHz+W+TxZTVF7tdmkicUlBXkRERBrMcRyONTm8MfogzhnUhgnfr+XM577lg4XraQr3phGJJQryIiIistdSE33ceFQXnr9gIC3Tk7hrkuUP/5nP2kLNPS8SLQryIiIiss965Kbx7HkDuPGoLsxdXcA542byyuzV1OhiWJGIU5AXERGR/eL1OJw7qA2vXXIQA9tm8PDnS7nslbksyStxuzSRJk1BXkRERA6IVulJPHp6H+45uQerC8r5zUuz+dfU5VRU17pdmkiTpCAvIiIiB4zjOJzYswVvXHIQJ/TI4dnpP3PBC7OYs6rA7dJEmhwFeRERETngMgN+7j6pB0+c0YeqmlqufO077v14McUVmqpS5EBRkBcREZGIGdYxm1cvOYgLBrfl7XlrOXvcTKYs2eh2WSJNgoK8iIiIRFSy38sfR3TmufMHkpns56aJC7jjvYXkl1a5XZpITFOQFxERkajo1TKNFy4YyG8P6cBnizdy9lQM50cAACAASURBVLiZfPpjnttlicQsBXkRERGJGp/Xw+XDO/DibwbRMj2RW99dyK3vLmBzaaXbpYnEHAV5ERERibquOSk8e/5Arj6sI18u3cTZz83ko4UbCAZ1IymRhlKQFxEREVf4PA6jh7bnpQsH0S4rmTGTFnHzxAVsLK5wuzSRmKAgLyIiIq7q3CyFsecO4LojOjF9xRbOeX4W7/+wXmfnRfZAQV5ERERc5/U4XDikHS9fOIhO2QH+8qHl+gk/sKFIZ+dFdkVBXkRERBqNDtkB/n1Of244qgszV+Zz9riZTJy3VmfnRXbCF6kXNsYMBe631o4wxnQFxgFBYD5wjbW2tt62GcBLQDqQANxgrZ1mjBkFPACsDG/6Z2vtlEjVLCIiIu7zehzOG9SGwzplc8/kH/nb5MV8Yjdyx/HdaJme5HZ5Io1GRM7IG2NuAcYCdb9tDwNjrLWHAw4wcrtdbgA+tdYeCVwCPBlePwi4xVo7IvylEC8iIhIn2mUl89TZ/bj56K58t6aAc5+fxXs/rNPZeZGwSA2tWQqMqvd4MFAXwj8Ajt1u+0eAf4eXfUB5vf0uNcZ8ZYx5yBgTsU8QREREpPHxOA5nD2zN+IsG0z0nhbs//JGbJi5gY4nmnReJSDC21r5ljOlYb5Vjra07fC4CMrbbPh/AGNOS0BCbP4af+hh4G/gJeAq4CvjH9u+XmpqIz+c9kD9Cg3i9HjIzA1F/X4ku9Tk+qM/xQX2OXZmZAV65cjjPT1vOQ58s5vwXZnH3qb05qU/LHbZVn+OD+hzBMfLbqa23nAbkb7+BMaYv8CpwU70hNM/WC/kTgTN29uLFLs03m5kZID+/1JX3luhRn+OD+hwf1OfYN6p3LgNbpvGXDy3XvTaX4+bmcMsxXclM9m/dRn2OD270OScnLarvtyfRmrVmjjFmRHj5JOCr+k8aY3oBbwDnW2s/CK9zgO+NMW3Dmx0DzIpOuSIiItJYdWoW4JnzBvC7Qzvy+eKNnPv8LL5cusntskSiLlpB/kbgbmPMNEKz0rwJYIyZbIxJAO4ldGHsY8aYL4wxE8NDcS4H/mOMmQIEgKejVK+IiIg0Yj6Pw6XD2jPugoFkB/zc+PYP/PVDS3FFtduliUSN0xSu/M7LK3Llh9BHd/FBfY4P6nN8UJ+bpsrqWsZOX8HzM1aSk5rI38/oR69myW6XJRHm0tAaJ6pvuAe6IZSIiIjEtASfh6sP68Qz5w0gyefh4nHf8vdPl1BWVeN2aSIRpSAvIiIiTUKfVum8dOEgRh/SgTfnruH8F2bx3eoCt8sSiRgFeREREWkykvxebj+pJ/86ux+1Qbji1e94fMoyKqtr97yzSIxp0PSTxphWQBZQDfwJeMJaOzeShYmIiIjsq8HtMhl/0SAem7KMF2euYvqKLfz15B50bZ7idmkiB0xDz8i/AOQC/0voJk2PRKwiERERkQMgJcHH7cd15+HTerOppJKLX5rN+FmrqG0CE32IQMODvA/4Esi01r4KRP82qiIiIiL74PAuzXjl4sEM65jNI18s49o357G+yJ2bSYocSA0N8gnAw8CXxpijiN4dYUVERET2W3YggQdH9uL247oxf20h5z0/i8mLNrhdlsh+aWiQvwSwwP1ADvCbSBUkIiIiEgmO43B6v1a8fOFgOmQnc8f7i7hz0iKKynUTKYlNDQ3ya4B3gEzAAJqYVURERGJSu6xknj53AFce0oGPF23gvBdmMWtlvttliey1hgb5l4FBwANAFfB/EatIREREJMJ8Hocrhndg7HkDSPR5+N3r32uaSok5DQ3yWcC7QBtr7X1AYuRKEhEREYmOuptInd6vFS/OXMUl4+ewZGOJ22WJNMjeXOx6IzDbGNMLSI1cSSIiIiLRk+z3cttx3baZpvL1OWsIappKaeQaGuRvBFoAfwOOAq6OWEUiIiIiLqibpvKg9pk88NkSbp64gPyyKrfLEtmlBgV5a+1/gSnAlcAqa+2MiFYlIiIi4oLsQAKPnN6H60d0ZupPm7lAF8JKI9agIG+MuRcYTehC14uNMQ9FtCoRERERl3gch/MHt+W58weQ5Pfyu9e/519Tl1Ndq6E20rg0dGjNEdbaM621jwJnAIdFsCYRERER1/XITePF3wzilN65PDv9Z6589TvWFJS7XZbIVg0N8n5jTN22HkCHpCIiItLkBRK83HWi4W8n92DZphIueHEWH9s8t8sSARoe5F8FphpjHgG+Cj8WERERiQsn9GzBSxcOomN2gNvfW8jfPvqRsirdH1Pc5dvdk+Gx8XVn31cDpwJzCc1gIyIiIhI32mYm8/Q5/fn3f1fw/IyVzF1dwL2n9qRbjmblFnfs6Yz8IsCGv94F7gl/txGuS0RERKTR8Xk9XHN4J548qy/FlTWMHj+Xd+at05zz4ordnpG31j4frUJEREREYsWQ9lm8fOEg7py0iHsm/8js1QX86ZiuJPu9bpcmcaShY+RFREREpJ5mKQk8cUZfrhjenkk/rOeSl+fw06ZSt8uSOKIgLyIiIrKPvB6HKw/pyBNn9GVLaRUXvzybDxaud7ssiRO7HVqzv4wxQ4H7rbUjjDFdgXGELp6dD1xjra2tt20y8BKhC2mLgIuttXnGmFOBu4Bq4Flr7dORrFlERERkbw3tmMVLFw5izPsLuWuSZc6qAm48qiuJPp0zlciJ2P9dxphbgLFAUnjVw8AYa+3hgAOM3G6X3wHzws+/AIwxxviBR4DjgSOBK40xLSNVs4iIiMi+apGWyD/P7s/FB7djwvfruHT8HFZuKXO7LGnCInlGfikwCngx/HgwMCW8/AGhcD6h3vaHAX+v9/ydQE9gibV2C4Ax5mvgcOCN+m+UmpqIzxf9i0u8Xg+ZmYGov69El/ocH9Tn+KA+xwe3+zzm1N4c2j2Hm9+ax0Uvz+Ghs/pxtNHM3Qea231uDCIW5K21bxljOtZb5Vhr6+ZmKgIyttslHSjY7vn663a1H8XFFQei5L2WmRkgP18XtTR16nN8UJ/jg/ocHxpDnwfmpvLibwZyy8QF/Pal2VwxvD2XD++Ax3FcraspcaPPOTlpUX2/PYnmwK3aestpQP52zxeG19d/vv66Xe0nIiIi0ui0Sk/i6XP786veuTw97WdufPsHisqr3S5LmpBoBvk5xpgR4eWTgK+2e34qcPJ2zy8Euhljso0xCcARwLQo1CoiIiKy35L8Xv58QnduPror05Zv4ZLxc1i6scTtsqSJiGaQvxG42xgzDUgA3gQwxkwOh/R/Ab3D4+CvBO621lYBNwAfEQrwz1prV0exZhEREZH94jgOZw9szVNn9aOksobR4+fwic1zuyxpApymcEvhvLwiV36IxjAGTyJPfY4P6nN8UJ/jQ2Puc15xBX96ZyHz1hZy0ZC2/O6wTvg8Gje/L1waI9+omqXJTUVERESiJCc1kX+f048z+rfihW9X8cf/zKOwvMrtsiRGKciLiIiIRJHf6+HWY7sx5vhuzFpZwOjxc1mxuXF+giCNm4K8iIiIiAtG9m3FP8/qR2F5NaPHz2XGii1ulyQxRkFeRERExCUD22Yw7oIB5KQmcN1b83hz7hq3S5IYoiAvIiIi4qI2Gck8c94AhnfK5v5Pl/D3T5dQXRv7k5FI5CnIi4iIiLgsNdHHgyN785uD2vLG3DX84S1dBCt7piAvIiIi0gh4PQ5/OLIzd53QndmrQhfBrsovc7ssacQU5EVEREQakVP7tORfZ/WjoKyKS8fPZf7aQrdLkkZKQV5ERESkkRnQNoNnzhtAIMHLVa9/z5QlG90uSRohBXkRERGRRqhDdoBnzx9A1+Yp3DxxAa/PWe12SdLIKMiLiIiINFLZgQSeOrsfR3RpxgOfLeXRL5ZRG9SMNhKiIC8iIiLSiCX5vdz/616cPaA1L89axR3vLaSiutbtsqQR8LldgIiIiIjsntfjcNPRXWidkcSjU5axqeR7HjqtD2lJinLxTGfkRURERGKA4zhccFBb/veUnsxbW8RvX/+OjSWVbpclLlKQFxEREYkhx5kcHjm9Nyu3lHHFq3NZXaC55uOVgryIiIhIjBnWMZt/ntWPovJqLn/lO5bklbhdkrhAQV5EREQkBvVtnc6/z+mP48CVr33Hd6sL3C5JokxBXkRERCRGdWmewthzB5AV8HPNm/OY+tNmt0uSKFKQFxEREYlhrTOS+L9z+tMxO8CNb//A5EUb3C5JokRBXkRERCTGNUsJ3TiqX6s07py0iEkL1rtdkkSBgryIiIhIE5Ca6OOxM/oyqF0mf/nAMnHeWrdLkghTkBcRERFpIpL9Xh45rTfDOmbxt8mLeWPuGrdLkgiK2u3AjDGJwHNAZ6AQuMZauzj83ADg0XqbDwNOA2YAPwLzw+snWGsfi1bNIiIiIrEmye/lwZG9ufXdBfz90yVU1dRy/uC2bpclERDN+/peARRba4cZYwzwD+AEAGvtXGAEgDHmLGCNtfZDY8yxwCvW2t9HsU4RERGRmJbg83D/r3sx5v1FPPLFMiqra7lkaHu3y5IDLJpDa3oBHwBYay3Qc/sNjDEpwN3AdeFVg4FBxpgpxpg3jDGtolWsiIiISCzzez38zyk9OaFHDk9+vZxnpq9wuyQ5wKJ5Rn4ucIox5m1gKNDGGOO11tbU2+Yy4A1r7cbw40XALGvtJ8aYC4AngDO3f+HU1ER8Pm+Ey9+R1+shMzMQ9feV6FKf44P6HB/U5/igPm/rsfMGcet/5vHU1BWkBhL57RGd3S7pgFCfoxvknyV0Fv5zYCqhgF6z3TYXsG1Q/wwoDS9PAP66sxcuLq44sJU2UGZmgPz80j1vKDFNfY4P6nN8UJ/jg/q8o1uP7kJZRRUPfvwjNVXVTWLMvBt9zslJi+r77Uk0h9YMAb621o4gFMqX1X/SGJMBJFprV9ZbPRY4I7x8DDArCnWKiIiINClej8NfTurBMd2b88gXy3h9zmq3S5IDIJpn5BcD9xhjbgLygcuMMTcAS6y17wDdgeXb7XMr8Kwx5mqgBLg8ivWKiIiINBk+j8PfTu5Bdc1CHvhsKT6Pw6j+rd0uS/aDEwwG3a5hv+XlFbnyQ+iju/igPscH9Tk+qM/xQX3evcrqWv707gK+XraZO4/vzq/7tnS7pH3i0tAaJ6pvuAe6IZSIiIhIHEnwebjv1F7hm0b9yKQF690uSfaRgryIiIhInEn0eXjg170Y3D6Tv35ombJkk9slyT5QkBcRERGJQ6E7wPbC5KZx+3sLmLUy3+2SZC8pyIuIiIjEqZQEH4+N6kObjGRufPsHFq0vcrsk2QsK8iIiIiJxLDPZzxNn9iUt0cfv35rP8s26UDhWKMiLiIiIxLnctET+cWZfHODaN+exrrDc7ZKkARTkRURERIQO2QGeOKMvxRXV/P6teWwprXS7JNkDBXkRERERAcDkpvLI6X1YW1jBH/4zn7KqGrdLkt1QkBcRERGRrQa2zeB/ftUTu6GY299bSHVt7N88tKlSkBcRERGRbRzZtRk3H92Vr5dt5oFPlxAMKsw3Rj63CxARERGRxufMAa1ZV1TB8zNW0jI9kdFD27tdkmxHQV5EREREdurqwzqyrrCcf369nNy0RE7ulet2SVKPgryIiIiI7JTHcbjrBMOmkkru+ehHclITGNI+y+2yJExj5EVERERklxJ8Hv7+6950yE7m5okLWLqxxO2SJExBXkRERER2Ky3Jx6On9yHZ7+WGt3/QHPONhIK8iIiIiOxRy/QkHhzZi00lldzyzgIqq2vdLinuKciLiIiISIP0bpXOXSd0Z+7qQu79ZLGmpXSZLnYVERERkQY7vkcLlm8u5elpP9O5WYALh7Rzu6S4pSAvIiIiInvliuEdWL65jCe+/In2WQGO7NrM7ZLikobWiIiIiMhecRyHu07oTs+Wadw5aSE/bih2u6S4pCAvIiIiInstye/lwZG9SEv0cfPEH8gvq3K7pLijIC8iIiIi+yQnNZG//7oXeSWVjHl/ITW1uvg1mhTkRURERGSf9W6Vzp+O6co3K/L559fL3S4nrkTtYldjTCLwHNAZKASusdYurvf848ChQFF41UjAD4wHkoE1wGhrbWm0ahYRERGRPRvZtxUL1hXzwrcr6dUylWO657hdUlyI5hn5K4Bia+0w4PfAP7Z7fhBwgrV2RPirALgLGG+tPRyYA/w2ivWKiIiISAPdeFQX+rZK4+4PLUs3lrhdTlyIZpDvBXwAYK21QM+6J4wxHqAb8H/GmKnGmEvDTx0GfBhe/gA4NnrlioiIiEhDJfg83HdqL5L9Xm55ZwHFFdVul9TkRXMe+bnAKcaYt4GhQBtjjNdaWwOkAE8ADwNe4HNjzEwgHSgI718EZOzshVNTE/H5vJGufwder4fMzEDU31eiS32OD+pzfFCf44P67J7MzAD/OG8gFz33Lfd8vJh/nT8Ij8eJyHupz9EN8s8SOgv/OTAVmBUO8QClwGN149+NMZ8B/QmNpU8DysLf83f2wsXFFZGtfBcyMwPk52vIflOnPscH9Tk+qM/xQX12V7fMJP54ZGce/Hwpj39suWRo+4i8jxt9zslJi+r77Uk0h9YMAb621o4AJgDL6j3XHfjaGOM1xvgJDamZTSjwnxze5iTgq+iVKyIiIiL74uyBrTnO5PDU1OXMWVWw5x1kn0QzyC8GfmeMmQbcA9xgjLnBGPNra+1C4GVgOjAFeMFa+wPwN+BcY8xUYDg7XiArIiIiIo2M4zjcflw3Wmckccf7C9lSWul2SU2SEwzG/sT9eXlFrvwQ+uguPqjP8UF9jg/qc3xQnxsPu6GYS8fPYVC7TB4b1QePc+DGy7s0tCYyA/73kW4IJSIiIiIRYVqkcuNRXZi+fAvPz1jpdjlNjoK8iIiIiETM6f1acXx4vPzsVTudt0T2kYK8iIiIiESM4zjcfnw32mYmc8d7i8gvrXK7pCZDQV5EREREIiolwce9p/SkoLyKeyb/SFO4RrMxUJAXERERkYjr3iKVaw/vxJdLNzHh+7Vul9MkKMiLiIiISFScO6gNwzpk8fAXy/hpk2YW2l8K8iIiIiISFR7H4c8ndifZ72XM+wuprK51u6SYpiAvIiIiIlHTPDWRMcd358e8Ev41dbnb5cQ0BXkRERERiaojuzbjjP6teGnmKr5ZscXtcmKWgryIiIiIRN0fj+xMp+wAd39oKSzXlJT7QkFeRERERKIuye/lrycbNpdW8eBnS90uJyYpyIuIiIiIK3rkpnHp0HZ8sHADXyze6HY5MUdBXkRERERcc+nQ9pgWqdz7yWLd9XUvKciLiIiIiGt8Xg9/OdFQWF7N/Z8udrucmKIgLyIiIiKu6pqTwpWHdOCTHzcyedEGt8uJGQryIiIiIuK6C4e0o3fLNP7+6RI2llS6XU5MUJAXEREREdf5PA5/PtFQVlXDfR8vJhgMul1So6cgLyIiIiKNQqdmAa46tCNTlm7iM81is0cK8iIiIiLSaJw3uC09WqTywGdLdaOoPVCQFxEREZFGw+dxuOP4buSXVvL4lz+5XU6jpiAvIiIiIo1Kj9w0zh/clonz1jFrZb7b5TRaCvIiIiIi0uhceUgH2mQk8b8fL6aiutbtcholBXkRERERaXSS/F5uO7YbP28p45npK9wup1HyReuNjDGJwHNAZ6AQuMZau7je89cD54YfTrLW3m2McYBVQN1206y1t0WrZhERERFxz9COWfyqdy4vfLuK40wO3XJS3S6pUYlakAeuAIqttcOMMQb4B3ACgDGmM3ABMBQIAl8ZYyYApcBsa+2pUaxTRERERBqJPx7Zmf8u28y9Hy9m7HkD8DiO2yU1GtEcWtML+ADAWmuBnvWeWwmcaK2tsdbWAn6gHBgMtDHGfG6MmRQ+ABARERGROJGZ7OePIzozb20R78xb53Y5jYoTrbtmGWOuJHTG/fLw96lAgrW2pt42DvAAkGat/a0x5ggg11r7hjHmMOARa+2Q7V+7rKwy6PN5o/Jz1Of1eqip0cUXTZ36HB/U5/igPscH9bnpCQaDXPDsDBavL+ajPxxOdkqCK332+72N6uOAaAZ5H6GQPpBQiD/OWntwveeTgGeBIuBqa22NMSYAVFtrK8PbrAHaWGu3KTovr8iVe/hmZgbIzy91460litTn+KA+xwf1OT6oz03T0o0lXPDibE7plcuYE7q70uecnLRGFeSjObRmCPC1tXYEMAFYVvdE+Ez8ROA7a+1v652l/zPwx/A2/YGftw/xIiIiItL0dWmewvmD2jBx/jq+W13gdjmNQjQvdl0M3GOMuQnIBy4zxtwALAG8wJFAojHmpPD2twH3AS8ZY34FVAOXRLFeEREREWlELh/egck2jwnz1nFk71Zul+O6qAV5a+1G4NjtVj9cbzlpF7v+KjIViYiIiEgsCSR4eeE3A2lU41tcFM0z8iIiIiIi+yU7kOB2CY2G7uwqIiIiIhKDFORFRERERGKQgryIiIiISAxSkBcRERERiUEK8iIiIiIiMUhBXkREREQkBinIi4iIiIjEIAV5EREREZEYpCAvIiIiIhKDnGAw6HYNIiIiIiKyl3RGXkREREQkBinIi4iIiIjEIAV5EREREZEY5HO7gFhkjPEA/wT6AxXA5dbaJe5WJfvKGOMHngU6AonA34AFwDggCMwHrrHW1hpj/gz8CqgG/mitneFGzbLvjDEtgFnAcYT6OA71uUkxxtwG/BpIIPS3egrqc5MS/rv9PKG/2zXAFej3uUkxxgwF7rfWjjDGdKWBvd3Vtm78DNGgM/L75jQgyVo7HLgVeMjlemT//AbYZK09HDgJ+AfwMDAmvM4BRhpjBgFHAkOBc4EnXapX9lH4H/9/A2XhVepzE2OMGQEcAhxKqI/tUJ+bopMBn7X2EOCvwP+gPjcZxphbgLFAUnjV3vR2h22jWXu0Kcjvm8OADwGstdOBg9wtR/bTG8Cd9R5XA4MJncUD+AA4llDfJ1trg9banwGfMSYnqpXK/noQeApYE36sPjc9JwDzgAnAu8B7qM9N0Y+EeuYB0oEq1OemZCkwqt7jventzrZtshTk9006UFDvcY0xRsOUYpS1tthaW2SMSQPeBMYAjrW2bm7WIiCDHftet15igDHmEiDPWvtRvdXqc9PTnNDJlbOAq4CXAY/63OQUExpWswh4Gngc/T43GdbatwgdnNXZm97ubNsmS0F+3xQCafUee6y11W4VI/vPGNMO+Bx40Vo7Hqg/ni4NyGfHvtetl9hwKXCcMeYLYADwAtCi3vPqc9OwCfjIWltprbVAOdv+Q64+Nw3XE+pzd0LXqz1P6JqIOupz07I3/ybvbNsmS0F+30wlND4PY8wwQh/jSowyxuQCk4E/WWufDa+eEx5rC6Fx818R6vsJxhiPMaY9oQO4jVEvWPaJtfYIa+2R1toRwFzgIuAD9bnJ+Ro40RjjGGNaAynAp+pzk7OFX87Gbgb86O92U7Y3vd3Ztk2WhoPsmwmEzuz9l9CFFKNdrkf2z+1AFnCnMaZurPwfgMeNMQnAQuBNa22NMeYrYBqhg+BrXKlWDqQbgafV56bDWvueMeYIYAa/9O8n1Oem5hHg2XAPEwj9HZ+J+txU7c3f6h22daPgaHGCweCetxIRERERkUZFQ2tERERERGKQgryIiIiISAxSkBcREfl/9u48Ps6q7v//a2ayTibJZF+atGmb5nQvtGXfSmlZVEAW9fYLKIji/tNbveXWG9zXW8VbQVxQxA1BEBAFpKW0lL3QFrqfJE33NHuz78n8/phpKaHQtM3kmuX9fDzyyOS65rrmMz2Z5j1nznWOiEgUUpAXEREREYlCCvIiIiIiIlFIQV5EREREJAopyIuIiIiIRCEFeRERERGRKKQgLyIiIiIShRTkRURERESikIK8iIiIiEgUUpAXEREREYlCCvIiIiIiIlFIQV5EREREJAopyIuIiIiIRCEFeRERERGRKKQgLyIiIiIShRTkRURERESikIK8iIiIiEgUUpAXEREREYlCCvIiIiIiIlFIQV5EREREJAopyIuIiIiIRCEFeRERERGRKKQgLyISgYwx9xhjvhS6/Zoxxn+E+3zJGHPPKM51lzFmQej2b40xS8aoxm8YY+4Yi3OJiMixS3C6ABEReWfW2pNO8BRLgV+HzvXRE69IREQigYK8iEiYGWPuBdZaa38S+vmTwCLgg8BPgdOBdMAFfNRa+/yI4wNAHtAG/JxgMG8A6kPbMMacDvwvkAwUAcuttTcaY74LFAN/McZ8CPghcIe19kFjzHuBrxP8dLYD+IK1do0x5htAWeg8k4B9wLXW2v3v8BxnAXcAOUAA+Im19o/GGB/we2AaMAysBT4OeI+03Vo7fCz/tiIi8UxDa0REwu8u4PrDfr4+tO00giH7DGvtTOAPwH+/w3k+BVQAMwmG+YmH7fsc8DVr7Wmh/ZcZYxZYa/8HqAWusda+fPDOxpjpwK+Aq6y184CvAf8wxmSE7nIO8D5r7XSgC/jE2xVljEkAHgVut9bOBS4BvmeMOQO4AkgPfapwSuiQKe+wXURERklBXkQk/FYBKcaYhcaYmQR711dYa18EbgE+boz5MXA14HuH8ywB7rXW9ltru4C/HLbvw4DfGPNV4E4g9SjnWhyqoQbAWvs0wV7+BQdrtta2h26vB7Lf4VwVQIq19qHQuWqBvwMXA88Bs4wxqwi+Sfk/a231O2wXEZFRUpAXEQkza20A+B3wIeAG4HfW2oAx5t3AY6G7/YNgD7nrKKc7fP/gYbdXA+8CtgHfIjgc5p3O5SE4BOZwbiAxdLvnsO2B4z2XtXYHUA58H8gAnjLGXPp229/hMUREZAQFeRGR8XEPcBnwPoJjwyE4POaf1tpfAq8C7yUYit/OE8CHjDEpxpgU4AMAoRltTgFuDvWKlxAMyQfPNcgbAf2gFcBFxpgpoXMsBkqBlzl224ABbNqK2AAAIABJREFUY8yVoXMVA1cBy0PXA/weWGatvRl4Epj/dtuP47FFROKWgryIyDiw1tYB64ANoaEnEOyBX2SM2Rjatx2YbIx5u/+bf00w8G8CngF2hM7dSrBne50xZhPBoSrPEwzzAA8BfzbGXHhYPVsIjrl/KHTMD4BLrbVtx/HcBgi+CfmcMWYD8BTwLWvtSuCPBN9QbDHGrAUyCV6w+3bbRURklFyBwMhPQ0VEREREJNKpR15EREREJAopyIuIiIiIRCEFeRERERGRKKQgLyIiIiIShRKcLmAsNDZ2OHLFrs+XTGdnnxMPLeNI7Rwf1M7xQe0cH9TO8cGJds7LSz/aWh/jSj3yJyAh4Z2me5ZYoXaOD2rn+KB2jg9q5/igdlaQFxERERGJSgryIiIiIiJRSEFeRERERCQKKciLiIiIiEQhBXkRERERkSikIC8iIiIiEoXCMo+8MSYRuBsoA5KB71hrHx1xHy+wHLjRWrsttG090Ba6yw5r7Q3GmNOBnwGDwDJr7TfDUbOIiIiISDQJ14JQ1wLN1trrjDE5wHrgUJA3xiwEfgWUHLYtBcBau2jEuX4FXAXUAI8ZY+Zba9eFqW4RERERkagQriD/APDgYT8PjtifDFwB/OmwbfMArzFmWaiurwJbgGRr7XYAY8yTwAWAgryIiIhIGHT2DbKvtZemrn4S3C58KQlMyfGSmqgFmCJNWIK8tbYTwBiTTjDQ3zJi//Oh/Ydv7gZ+DPwWmAY8AZwHtB92nw5gysjH8/mSHVndy+Nx4/d7x/1xZXypneOD2jk+qJ3jg9r52DV29PG3tXt5elsDG2vbCATevN/tgoqCdN49u5DLT5pAUWaKM4UeRu0cvh55jDGlwMPAndbae0dxSCVQba0NAJXGmGbAA6Qfdp90oHXkgZ2dfWNQ8bHz+720tnY78tgyftTO8UHtHB/UzvFB7Tx6zV39/PqFnfxzUz2DwwHmFGVw42kTmZaXRq4vmeHhAK09A1Q2drJmVys/eaqKnz1dzeVzCrnx9Ink+ZIdq92Jds7LSz/6ncZRuC52LQCWAZ+x1q4Y5WEfAeYAnzLGFAMZwD6g3xgzleAY+YsAXewqIiIicgICgQAPb6zj58/U0Ds4zJVzi/jAycVMyj5yD/eiabncdCbsa+vhT6/s5R8b6/j31ga+sGgql84uwOVyjfMzEAhfj/xXgSzgVmPMraFtdwFp1trfvM0xvwPuMcY8BwSAj1hrB40xnwD+QrB3fpm19uUw1SwiIiIS8zr7BvnOskpWVDZxykQ/X76gnLK3CfAjTchM5b+XTOOaBSV8e1kl315WyYs7W/jaxUZj6B3gCowcBBWFGhs7HHkS+uguPqid44PaOT6oneOD2vnt1Xf08Z8Pb6KmuZtPn13GNQtLcB9nb/pwIMCfXtnLL57dQUW+j59eMWtch9o4NLQmoj560IJQIiIiInFg94EePnLvemrbevnZFbO57pTS4w7xAG6Xiw+fWspPr5jNngM9fPz+16lr7x3DiuVoFORFREREYtze1h4++bfX6R8K8JsPzOO0sqwxO/dZU7K5/eo5tHQP8PG/baDRoUlI4pGCvIiIiEgMa+nu59MPbKBvcJhfXD2HinzfmD/G3OIMfnH1HA509/P5hzbR1T9yCSEJBwV5ERERkRjVPzjMf/1jC83dA/zsqvCE+INmFWXwg0tnsr2pi//+51aGhqP/OsxIpyAvIiIiEoMCgQDfXV7Jhtp2vnGxYVZh+OdAP3NyNjcvmcZLOw/w6xd2hv3x4p2CvIiIiEgMum99LY9vaeCmMyexxOSN2+NeMbeIy+cU8vuX97B6e/O4PW48UpAXERERiTG2oZPbV9dw9pRsPnr6xHF//P9aXM70fB/f+relSRe/ho2CvIiIiEgM6RkY4pbHtpKZksjXLzKOrLqanODm2++eTu/gMN9eVkksrFsUiRTkRURERGLI/62qYVdLD9+8xOD3JjpWR1m2l8+eM5kXdhzg4Y11jtURyxTkRURERGLE2j2tPLRhP9csLOHUSWM3V/zxet/JxSwszeT21TU0d/U7XU7MUZAXERERiQG9A0N8b3kVJf4UPn7mJKfLAYKrv958wTR6B4b5+eoap8uJOQryIiIiIjHg7pd3s/tAD19ZMo2URI/T5RxSluPlQ6eU8PiWBtbuaXW6nJiiIC8iIiIS5bY3dfHHV/bynlkFETGkZqQbTptIcUYyP3yqmsGhYafLiRkK8iIiIiJRLBAIcNvK7aQlefjceVOcLueIUhI9fOH8qexo6eYfm3Th61hRkBcRERGJYs/WtLBmdys3nTEJf6pzs9QczblTczhpQga/eWEX3f1DTpcTExTkRURERKLUwNAwP3umhrLsVK6aV+R0Oe/I5XLxmXMm09I9wF/X7XW6nJigIC8iIiISpR54rZbdB3r4/KKpJHgiP9bNm5DJovIc/vTKXg50azrKExX5LS4iIiIib9HZN8jdL+3m9ElZnDU52+lyRu1TZ0+mZ2CIP6xRr/yJUpAXERERiUL3rdtHW+8gnzy7zOlSjsnkHC8XTc/n76/X0to94HQ5UU1BXkRERCTKtPUM8OdX97KoPIeZhelOl3PMrj+tlL7BYY2VP0EK8iIiIiJR5i9r99LdP8THzyxzupTjMiUnjcUVudy/vpaO3kGny4laCvIiIiIiUeRAdz/3rdvHEpNHeV6a0+UctxtOnUhX/xAPvFbrdClRS0FeREREJIr8Yc1e+gaHuemMSU6XckJMgY+zp2Rz79q99A5oXvnjoSB/Arr6Bvn18zv57Yu7qG7sIhAIOF2SiIiIxLDWngH+/notF03PpyzH63Q5J+zahSW09Q7yxNYGp0uJSgljfUJjTCJwN1AGJAPfsdY+OuI+XmA5cKO1dtth2/OBtcBSa+02Y8x84J9AVeguv7TW3j/WNR+vX6zazm9f2g3Ar1/YxaSsVJaYPJaaPKbmRu9HXSIiIhKZHnitlt7BYT50aqnTpYyJ+SWZVOSlcd+6fbx3TiEul8vpkqLKmAd54Fqg2Vp7nTEmB1gPHAryxpiFwK+AksMPCr0B+DXQc9jm+cBt1tqfhKHOE/bo67WcPy2XL19QzjPVTTxV2cTvX97N717azeQcL0tNHksr8mLiHbOIiIg4q2dgiPvX7ePsKdmUx0iHocvl4oMLJvDNf1eyZncrp03KcrqkqBKOIP8A8OBhP4+8FDkZuAL404jtPyYY8L9y2LYFgDHGXE6wV/7z1tqOsS33+AwOB2js7GNKTgG5aUlcNa+Yq+YV09TVz9OVTTxV2chdL+ziNy/sYlpeGksqgj31pVmpTpcuIiIiUejRjXW09Q5yfYz0xh90ocnn9tU7uG/dPgX5YzTmQd5a2wlgjEknGOhvGbH/+dD+Q9uMMdcDjdbaJ40xhwf5NcBvrbVrjTH/A3wd+NLIx/T5kklI8IzxM3ln9e29DAdgYp4Pv/+NHne/30v5BD83nV9OXXsvT26u4/FNdfzy+Z388vmdzCzK4F2zC3nXnEJKs9RTHw08Hveb2lhik9o5Pqid40MstvPA0DB/Xb+PBRP9nDeryOlyxty1p03i5yurOTAYYPIoP22IxXY+VuHokccYUwo8DNxprb13FId8BAgYY5YAJwF/NMZcBjxsrW0N3edh4PYjHdzZ2TcGVR+bmvrgBwNpbmht7T7ifVKAy2fkc/mMfOrae1kR6qn/8fJKfry8kpmF6SypyGWpyaMwI2Ucq5dj4fd737aNJXaoneOD2jk+xGI7P7G1nn2tvXxx0dSYe24A7zK53PnMdu55rob/XDR1VMc40c55eZG1+FY4LnYtAJYBn7HWrhjNMdbacw87fhXwCWttnTHmZWPMZ621a4ALCF4IGxEaO/sByPUlj+r+hRkpXLOwhGsWllDb1suKykaW20Z+vnoHP1+9gzlFGSwxuSypyCM/fXTnFBERkdgXCAT40yt7mZLj5awp2U6XExY5aUksKs/lsc31fOrsySQnaGLF0QhHj/xXgSzgVmPMraFtdwFp1trfHOO5PgncYYzpB+qAm8auzBPT1BUK8mlJx3xscWYK151SynWnlLLnQA9PVTbylG3kp6tq+OmqGk6akMFSk8fiabmjfqMgIiIisWn9vjaqGru45cJpuGN4Vpcr5hbyVGUjK6uauHhGvtPlRAVXLMx93tjYMe5P4pEN+/nFczt54uOnkeAZm3eNO1u6D/XUb2/qxgWcXJIZDPUVuWR7j/1Ng5y4WPyIVt5K7Rwf1M7xIdba+eZHt7B2Tyv/uuk0UhLH95rA8TQcCHDV3a+Q70vm1x+Yd9T7OzS0JqLeSSnIH6fB4QCJqUkE+gbCcv6a5i6essFQv7OlB7cLFpT6WWLyWFyei9+bGJbHlbeKtT8IcmRq5/igdo4PsdTOde29vPe3a7hmYSmfPXey0+WE3R/W7OGOZ3fwwPULjzp9t4K8VnY9bgluF5mp4QvTU3LSuOnMMv52/UL++qEFXH/aROo7+vj+8iou/tWLfPbvG4PTUPWE542EiIiIOO/B1/cTAK4+KfZmqjmS98wqwON28fDG/U6XEhXCMmuNjB2Xy0V5XhrleWl84sxJVDa+0VP/7WWVfP8pF6dNymKJyeW8qbmkp6hJRUREYkHvwBCPbNjPeeW5FMXJ7HY5aUmcNzWHx7c08NlzJo/Z8OVYpdQXRVwuFybfh8n38amzy9jW0Hko1H/z3y0kuKs4vSyLpSaPc6fm4EtW84qIiESrZdsaaesd5AMnFztdyrh696wCnq5q4oWdBzh3ao7T5UQ0Jb0o5XK5mFGQzoyCdD5zzmS21HWw3AbnqX+upoVEj4szyrJZYnI5Z4pCvYiISDQJBALcv34fU3O9zC/JdLqccXVmWRb+1EQe31KvIH8USncxwOVyMasog1lFGXzuvMls2t9xaErL1dubSfK4OHNyNksq8jh7ajZpSWp2ERGRSLalvpPKxi5uvqAcVwxPOXkkCR43F03P4+EN+2nvHSAjRRN8vB0luhjjcrmYU5zBnOIMPnfeFDbWtvNUZRMrKhtZVd1McoI7FOpzOXtKDt6k2J3GSkREJFo9vGE/KQnuuJ1P/d2zCrh/fS1PVTZx5dz4uND3eCjIxzC3y8W8CZnMm5DJfy6awoZ97TxV2ciKyiZWVjWRnODm7CnBnvqzpmSTGsNz04qIiESLzr5Blm1r4KLp+XE7NHZ6vo/JOV4e31yvIP8O4vO3Iw65XS5OKsnkpJJM/nPRVF6vbeMpG+ypX1HZREqCm7On5LDU5HLm5OyYXnBCREQkki3b1kDPwDBXzC10uhTHuFwu3jUjn188t5O9rT2U+FOdLikiKcjHIY/bxfwSP/NL/Hzx/Km8tq+N5Ta4JPJTlY2kJro5a3I250zN4czJ2fjDOF++iIiIvNnDG+qYlpfGzMJ0p0tx1MWhIL/cNnLDaROdLiciKcjHOY/bxYJSPwtK/fzX4nLW7w2G+me2N/NUZRNuF8wpyuCcqTmcPSWbKTneuLvoRkREZLxsre9gW0MnX47Di1xHKsxIYW5xhoL8O1CQl0M8bhcLJ/pZONHPzUvK2VbfybPbm3m2poU7nt3BHc/uoDgzhXOmZHPOlBxOKskkOUELNYiIiIyVhzfsJznBzSVxepHrSEtNHj9ZuZ2dzd2U5XidLifiKMjLEbldLmYWpjOzMJ2Pn1VGQ0cfz9UEQ/0jG+u4f30tSR4XcydkcupEPwtL/cwoTCfBHd+9ByIiIserZ2CIJ7c2stTkxe1FriNdUJHLbSu3s9w28rEzJzldTsTRb4mMSn56MlfOK+bKecX0Dgzx6p5WXtkd/LrzuZ0ApCV5OLkkk4WlfuYWZ2DyfSSpx15ERGRUVlY10T0wxKWzC5wuJWLk+ZI5qSST5baRj54xMe6HG42kIC/HLCXRw9lTcjh7SnC1tQPd/by6p41Xd7fyyu4DPFfTAkCSx4XJT2dOcTpzizOYXZRBvi9JL0IREZEj+NfmeiZkpnDShPhayfVolpo8/ndFNdubuynPTXO6nIiiIC8nLMubxFKTx1KTB0BjZx8ba9vZUNvBpv3tPPhaLfeu3QdAZkoC0/J9VOSlUZ6bRkWej7Icr8bai4hIXKtr7+XV3a187IxJuNXh9SaLp+Xy46erWW4bFeRHUJCXMZfnS2ZxRR6LK4LBfmBomMqGTjbXdVDZ2EV1Yxd/f30/fYPDAHhcUJqVSqk/ldKsVCYedrsgPVn/oYmISMx7YmsDAeBds3SR60g5aUnML/WzsrKJT55V5nQ5EUVBXsIu0eNmVlEGs4oyDm0bGg6wp7WH6sYuqho7qWnuZk9rD2t2tx4K+BAcnlOYkUJ+ejIF6ckU+JKC39NTyE8P3k5PTtBwHRERiVqBQIB/ba5nfkkmEzK18NGRnF+ew4+e3s7Olm7KsjV7zUEK8uIIj9tFWbaXsmwvS0JDcgCGAwEaOvrY29rL7tYe9hzooa69l/qOfl7ZdYCmrn6GA28+V2qim9y0JLK9SWSnJZHtTSTHm0R2WmJwmzf0PS0Rb6JHoV9ERCLKxv0d7D7Qw4dPLXW6lIh17tRgkF9d3UzZqQryBynIS0Rxu4I98IUZKSyc6H/L/sHhAM1d/dR39NHQ0Ud96Kupq5+W7n52Nnezbk8/bb2DRzx/coKbHG9iKPAnkeVNJMebSE5aEjlpSeQe9j0l0RPupysiIsJjm+tJSXBzQUWu06VErMKMFGYU+FhV3cyH9IbnEAV5iSoJbldoaE3yO95vcGiYAz0DtHQN0NwdDPlv3B6gpauf2rZeNu1vp7Vn4C29/AC+ZA+5aUkUZqaSmewhNy2ZXF8w5B/68iVprl8RETluvQNDLLMNLK7IJS1Jf0/eyXnlOfz6+V00dfaR63vnHBAv9BsjMSnB4ybPl0zeKF7oQ8MBWnsGaOrqp6mrn+bO/kO3m7r6ae0dZGNzF01d/fQPvTXxpyV5KMxIpjA9hYL0ZAozkg+92SjMSCbfl0yiR7PyiIjIW63e3kxn3xDvnqm544/mvPJcfvX8LlbXtHDl3CKny4kICvIS9zxu16GhNeYI+/1+L62t3QQCATr6BoMB/2DY7+ynobOPuvY+6jr62FzXQWvPwJuOdxG84r4oI4USfwoTMlOY4E+hJDOVCf4UctKSNDOPiEicemJrA/m+pCMOJ5U3m5rjpcSfwjPVTQryIQryIqPkcrnISEkkIyWRKTlvP49t78AQ9R3BYF/fHhzDv7+9l/3tvby2r40ntzW8aShPcoKb4sxQwM9MocSfeuh7UUayxuqLiMSo1p4BXtx5gA/On6AOnVFwuVwsKs/l/vX76OwbRG99whDkjTGJwN1AGZAMfMda++iI+3iB5cCN1tpth23PB9YCS62124wx5cA9QADYBHzaWjuMSARLSfQwKdvLpLeZHmtgaJj97X3sa+thb2sv+1p72dfWw762XtbuaaVn4M2/4gXpyUzKSg2eMyuVSdnB25pjX0Qkuj1d1cTQcICLp2vu+NFaVJ7Dn1/dyws7Wnh/QcbRD4hx4eiRvxZottZeZ4zJAdYDh4K8MWYh8Cug5PCDQm8Afg30HLb5NuAWa+0qY8yvgMuBh8NQs8i4SfS4mRha+GqkQCDAgZ6BULjvZW9rD7sP9LDrQA+Pb6mnq3/o0H2TE4LnmZSVysRDIT/4XRfgiohEvmXbGpiUlUpFvlYrHa3ZRRlkexN5YecB3n96mdPlOC4cf+0fAB487OeR8wAmA1cAfxqx/ccEA/5XDtu2AHgmdPsJ4EIU5CWGuVyu0Nz3ScwpfnNPQyAQoLl7gF0t3ew60MOulm52H+jBNnTydFXTm4br5KQlHeq9L8v2MiXHy5ScNPJ8SZpHX0QkAjR09LFuTxsfO3OS/l8+Bh63i68urSA5Qf9mEIYgb63tBDDGpBMM9LeM2P98aP+hbcaY64FGa+2TxpjDg7zLWnswnnQAmUd6TJ8vmYSE8R9H7PG48fu1KEGsi6R2zsqC8glvHRXYPzjM7pZuapq62NHUdej7yqpmWnvqDt0vIyWB8nwf0/J9h75Py/eR50uO+z8kkdTOEj5q5/gQDe380OZ6AsD7Tp0Y8bVGmssXBv+9oqGdwy0sn78bY0oJ9pzfaa29dxSHfAQIGGOWACcBfzTGXAYcPlg4HWg90sGdnX0nWPHxOTibicS2aGnn3CQ3ucXpnFqc/qbtB7r7qWnuZntTNzXNXdQ0d/PvTXVvWjQrIyXhUK/9lBwvU3K9TM1NI9ubNN5PwzHR0s5yYtTO8SEa2vmR9fuYUeDD73FFfK2Ryol2zstLP/qdxlE4LnYtAJYBn7HWrhjNMdbacw87fhXwCWttnTFmvTFmkbV2FXAJsHKs6xWJdVneJBZ4k1hQ+kZPfiAQoKV7IBjsm7qpaQ6G/OW2kY6+NwK+PzWR8rw0puWmMS0vjYo8H2U5XpITNC++iMjx2tXSzdb6Tv5z0RSnS5EoF44e+a8CWcCtxphbQ9vuAtKstb85xnN9EbjLGJMEbOXNY+9F5Di5XG/MnX/KxKxD2wOBAE1d/dQ0dbM9FPKrmrp4aMN++gaDH5B5XDAp28u0vDSm5flC39PITdP4exGR0Vi2rREXsNTkOV2KRDlXIHCEtemjTGNjhyNPIho+upMTp3YOrn67p7WH6sYuqho7qWzsorqxi7qON4a1Hey9r8hLozw32Hs/OcdLUpT03qud44PaOT5EcjsHAgHe9/tXyfMl8cv3z3O6nKjm0NCaiOqx0hx1InJUHreLsmwvZdlelhzWg9TeO0BVKNRXNXZR2djJ319/o/c+we1iSo6X6QU+TH46Jj+NinwfqVrkSkTilG3oZNeBHq5ZWHL0O4schYK8iBy3jJREFpT63zT+fmg4wJ4DPVQ2dmIbuqhs6GT19hYe3VQPgNsFk7K8mAIfJt/H9Pzg9/QU/XckIrHvyW2NJLhdLJ6W63QpEgP0l1NExpTH7aIsx0tZjpcLpwe3BQIB6jv6sA1d2IYObEMX6/a08u+tDYeOK85MYUaBj5kF6cwsTGd6gU8LW4lITAkEAiy3jZxelkVmaqLT5UgM0F9JEQk7l8tFYUYKhRkpnFeec2j7ge5+bEMn2+o7sQ2dbK3vZEVlU/AYYFJ2KjML05lZkM6MwnQq8tJI0bAcEYlSm/Z3UN/Rx6fOLnO6FIkRCvIi4pgsbxKnl2Vzeln2oW2tPQNsre9gS10HW+o6WbOrlce3BHvuPW4XU3O8wXAf+pqa4yXBEx0X1IpIfFtR2USC28W5U3OOfmeRUVCQF5GI4k9N5IyybM44LNw3dPQFg30o4D9d1cQjG4Mr1iYnuKnI8zGz0Heo935idipuTYUpIhEkEAjwdFVwWI2GDcpY0W+SiES8/PRk8tOTWRS6OCwQCLCvrZctdR1srutga10Hj26q4/71tQCkJXmYUeBjdlFG6CudnLT4WaVWRCLPlroO9rf3cdOZk5wuRWKIgryIRB2Xy0WJP5USfyoXTs8HgrPl7GjpDg3JCX796dW9DA0Hl5kozkhmdlEGs4rSmVOUgcn3Rc0c9yIS/TSsRsJBQV5EYoLH7aI8N7gY1WWzCwHoHRjCNnSyaX8Hm/a383ptO8tsIwCJHhcVeT5mF6UzuyiDM00+6a6AVqcVkTEXCARYUdnIqZP8ZKRothoZOwryIhKzUhI9zJuQybwJmYe2NXb2HQr2G/d38I+NoSE5j28jKzXxUI/97KLgxbQayyoiJ2prfSe17X3ceIaG1cjY0l8oEYkreb5kzp+WzPmh8faDwwG2N3WxvbWXV2qa2bS/nedqWoDgFJiTc7yHeu3nFGUwOceLx61eexEZvRWVTXjcLs7TsBoZYwryIhLXEtwuTL6P0yryeVdFMNy39w6wpa6DjaGe+1XVzYdWpvUmephZlM6cQ+E+nSyvLqQVkSM7OKzmlIl+LQIlY05BXkRkhIyUxDfNbx8IBNjT2svG2nY27W9n0/4O/rhmD0PB62gp8accCvWzizKoyEvT3PYiAkBlQxf72nq54bRSp0uRGKQgLyJyFC6Xi4lZqUzMSuXdswqA4IW0W+s72Vjbzsb97byyu5V/bw0uXJWc4D40/eXBcJ+fnuzkUxARhzxV2YjHBeeV5zpdisQgBXkRkeOQkujh5JJMTi4JXkgbCASo7+g7NBxnY20H96/fx59fDXbb5/uSmFOccehC2ukF6SRr+kuRmHZwWM3CiX78GlYjYaAgLyIyBlwuF4UZKRRmpLDU5AHQPzhMZWNnMNyHhuWsqGwCgmPzK/J9b4y1L06nOCNF01+KxJCqxi72tPZy3SkaViPhoSAvIhImSQnuQ6vLMn8CAE1d/WwOTX25sbb9jekvgWxv4qGVaOcUZTCzMB1vksfJpyAiJ2BFaFjNonLNViPhoSAvIjKOctOSOK8899B42YPTXx6c135TbTurtzcD4HZBeW4ac4ozmBv6mpCpXnuRaLGyqpmTS/2a2UrCRkFeRMRBB6e/NPk+rpoX3NbWM8CmumCP/cbadp7Y0sDfX98PvNFrP7c4OBxnZkE6KYnqtReJNDtbutnR0s3VJxU5XYrEMAV5EZEIk5mayFmTszlrcnD6y6HhADXNXWysbWdDaEjOwV57j9tFRV5aMNgXZTCnOIOijGT12os4bFVV8HoYzVYj4aQgLyIS4TxuF9PyfEzL83FlqNe+tXuAjfuDU19uGDHWPictKRTs05lbnKEZckQcsKq6mZmF6RRo6lkJIwV5EZEo5Pcmcs7UHM4JLfk+OBxge2MXr4fmtd9Y287KqjdmyDH5vtBwnGDAL8xIcbJ8kZjW0NHH5roOPnV2mdOlSIxTkBcRiQEJbhemwIcp8PH+k4sBaO7qZ1Oox35jbTsPbdjPX9ftA4Lz2r8R7DMw+T6S1GsvMiaeCQ19W6RhNRJmCvIiIjEqZ+QMOUPDVDZ2HQr2G/e381TOnZT0AAAgAElEQVRoXvskj4vZRRksKM1kQamf2UUZGo4jcpxWVTUxKSuVyTlep0uRGDfmQd4YkwjcDZQBycB3rLWPjriPF1gO3Git3WaM8QB3AQYYAm6w1m43xswH/glUhQ79pbX2/rGuWUQkHiR43MwsTGdmYTr/EZrXvrGzj4217bxe2876vW387qXd3PXibhIPBvuSg8Fes+OIjEZ77wBr97Zx7cISp0uROBCOHvlrgWZr7XXGmBxgPXAoyBtjFgK/Ag7/Db8UwFp7ljFmEXAbcDkwH7jNWvuTMNQpIhL38nzJLK7IY3FFcDXajt5BXtvXxto9bazb28rdL+/mty8Fg/2cogzOKMvijLJspuWn4dbMOCJv8VxNC0PDAS0CJeMiHEH+AeDBw34eHLE/GbgC+NPBDdbaR4wx/wr9OAmoD91eABhjzOUEe+U/b63tCEPNIiICpKckvOki2s6+YLB/dXcba3Yf4BfP7eQXz+0k25vI6aFQf9okLXgjctCq6mbyfEnMLEx3uhSJA2Me5K21nQDGmHSCgf6WEfufD+0fedygMeYPBEP+1aHNa4DfWmvXGmP+B/g68KWRj+nzJZOQMP4f+Xo8bvx+jX+LdWrn+KB2PjI/UFKQwXvmlwLQ0NHLc9XNPFvVxPPbm3h8SwMuF8wuzuC8aXksmVHAzKL0iJ3HXu0cH5xq596BIV7aeYArT55AdlbauD9+vNHrOUwXuxpjSoGHgTuttfeO9jhr7YeNMTcDLxtjZgIPW2tbQ7sfBm4/0nGdnX0nWvJx8fu9tLZ2O/LYMn7UzvFB7Tw6ScDiyVksnpzF0HA52xo6eWlnCy/uOMCdz2znjlXbKUxP5rzyHM6flsu8CZkkuCMn1Kud44NT7fxMdRM9A0OcUZqp37Nx4EQ75+VF1ict4bjYtQBYBnzGWrtilMdcB5RYa78PdAPDBC96fdoY81lr7RrgAmDtWNcrIiLHx+N2MaswnVmF6dx4+iQOdPfz7PYWVlU38fCG/dy/vpbMlATOnZrDRTPyWVjqxxNBoV5krK2sbiY9OYEFpZlOlyJxIhw98l8FsoBbjTG3hrbdBaRZa3/zNsc8BPzeGLMaSCQ4Fr7XGPNJ4A5jTD9QB9wUhnpFRGQMZHmTuGxOIZfNKaS7f4iXdrawsrqZp6ua+OfmenLSklhq8rh4eh4zCyN3+I3I8RgcDvDc9mbOnpJNgkdTt8r4cAUCAadrOGGNjR2OPAl9RBsf1M7xQe0cPr0DQ7ywo4V/b2vkuZpmBoYClPpTeM+sQi6dXUCeb/yWsFc7xwcn2vnV3a188oEN/PCymSyepoWgxoNDQ2siqgdCC0KJiEhYpSR6Dk1x2dE7yMrqJp7YUs8vn9/Jb17YyTlTc3jvnCJOL8vS0BuJWquqm0hOcHNGWZbTpUgcUZAXEZFxk56SwGWzC7lsdiF7DvTwyMY6/rW5jlXVzRSkJ3PF3EKunFuk6SwlqgQCAVZVN3PapCxStXCajCMN4hIREUeUZqXy2XMn86+bTuMHl85gUlYqv3p+F5fetYbvLqukprnL6RJFRmVbQyf1HX1aBErGnXrkRUTEUYkeNxdU5HFBRR41zV38de0+ntjawCMb6zhzchYfOW0i8yZoFhCJXKuqmnC7OLSQmsh4UY+8iIhEjCk5afzPhRX882On8vEzJ7G1rpOP3vc6n35gA6/tbXO6PJEjWlndzMklmfhTE50uReLMqHrkjTFFBKeUHARuBm631r4WzsJERCR+ZXmT+OgZk7hmYQkPvlbLn1/dy8fuf52FE/3cdMYkTi5RD71Ehl0t3exo7ubKuVOdLkXi0Gh75P8IFADfA5YDPw1bRSIiIiGpiR6uO6WUf3z0VD5/3hRqmrq46f7X+dIjm9nVomkkxXmrqpsBND5eHDHaIJ8ArAb81tr7AF2SLSIi4yYl0cM1C0v4x0dP5VNnl/HK7lY+8Ie1/Pjpalp7BpwuT+LYM9VNTM/3UZiR4nQpEodGG+STgNuA1caY89FFsiIi4oCURA83nDaRh248hctnF/LAa7Vc8bs13Lt2L4PD0b/AoUSXxs4+Nu7vYNE09caLM0Yb5K8HLPBDIA+4NlwFiYiIHE1OWhJfWTqNez+0gDlFGfx0VQ0f/vM6Nu9vd7o0iSPPHBpWo5VcxRmjDfK1wKOAHzDAUNgqEhERGaWpuWn87MrZ/PCymRzoGeCGe1/jf1dU09k36HRpEgeeqW6m1J/ClByv06VInBptkP8LMB/4ETAA/CZsFYmIiBwDl8vF4mm5/O36hbz/5GIefK2W9/3+VZ7f0eJ0aRLDOvsGeXVPK4vKc3G5XE6XI3FqtEE+C/gnMMFa+wMgOXwliYiIHDtfcgJfWlzO7685mczUBD7/0CZ+8FQVPQP6EFnG3gs7WhgcDnCeZqsRBx3Lxa5fBNYZY2YCvvCVJCIicvxmFabzh2vmc82CEh56fT/X/mkdmzR2XsbYqupmsr2JzC7KcLoUiWOjDfJfBPKB7wDnA58KW0UiIiInKDnBzecXTeGX759L/+AwN/71NX7/8m6GNbONjIH+wWFe2NHCOVNz8Lg1rEacM6ogb619AXgGuAnYa61dE9aqRERExsCCUj9//fAClpo87nxuJzf9ZR1tmndeTtCre1rp6h/SIlDiuFEFeWPM94EbCF7o+mFjzE/CWpWIiMgY8SUn8O13TefmC8p5YXsT1/15HZvrOpwuS6LYM9XNpCa6OWViltOlSJwb7dCac621V1tr/w+4Cjg7jDWJiIiMKZfLxdUnFXPfR08nEICP3fcaD23Y73RZEoWGAwFWb2/mzMnZJCeMNkaJhMdofwMTjTEH7+sGNMhQRESiztySTP503XwWlvr5/vIqfrJyu1aElWOypa6Dpq5+zp2qYTXivNEG+fuA540xPwWeDf0sIiISdfypifz0itl8cP4E7lu3jy8+skkLSMmorapuxuOCs6dkO12KCAnvtDM0Nv5gV8U+4FLgNYIz2IiIiEQlj9vFF86fSlmOl/9dUc1H/voaP7tyNkUZKU6XJhHumeom5pf6yUhJdLoUkaP2yG8DbOjrn8C3Q99tmOsSEREJuyvnFnH7VbNp6uznxr++RnVTl9MlSQTb2dLNzpYezVYjEeMde+SttX8Yr0JERESccMrELH7zH/P4//6+kZvue53b3juLk0oynS5LItDq6mYAjY+XiPGOQf54GGMSgbuBMiAZ+I619tER9/ECy4EbrbXbjDEe4C7AAEPADdba7caYcuAegsN7NgGfttYOj3XNIiIS38pz0/jdB0/iMw9u5DN/38j33jNDYU3eYlV1MzMKfBRqCJZEiHDMm3Qt0GytPQe4BLjj8J3GmIXAamDqYZsvBbDWngV8DbgttP024JbQuVzA5WGoV0REhKKMFH77H/OYmpvGl/+xmeW20emSJII0dfaxaX+73uBJRAlHkH8AuPWwn0dOBZAMXEFw/D0A1tpHCK4aCzAJqA/dXkBwRVmAJ4AlY12siIjIQVneJO583xzmFGdwy2Nb+ffWBqdLkgixuqaFALCoPNfpUkQOGfOhNdbaTgBjTDrwIHDLiP3Ph/aPPG7QGPMHgiH/6tBml7X24Kw5HcARBy36fMkkJHjG6imMmsfjxu/3jvvjyvhSO8cHtXN8GE07+4F7bjiVj/9lHV9/YhspqYm896QJ41OgjIlwvJ5f2HmA0qxUFpTn4nK5xvTccnz0/3YYgjyAMaYUeBi401p772iPs9Z+2BhzM/CyMWYmcPh4+HSg9UjHdXb2nUi5x83v99La2u3IY8v4UTvHB7VzfDiWdv7xpTP4wiOb+fLfN9LZ1cd7ZhWGuToZK2P9eu7qH+SFmmbed1IxbW09Y3ZeOTFO/L+dl5c+ro93NGM+tMYYUwAsA2621t49ymOuM8Z8JfRjN8EAPwSsN8YsCm2/hOBiVCIiImGXkujhtvfO4tRJfr79ZCUrKjVmPl69uOMAA0MBDauRiBOOMfJfBbKAW40xq0Jf1xhjbnqHYx4CTjbGrAaeBD5vre0Fvgh80xjzIpBEcKiOiIjIuEhJ9PCjy2cxpyiDWx7bxgs7WpwuSRywqroJf2oic4sznC5F5E1cgUDg6PeKcI2NHY48CX0UHx/UzvFB7RwfjredO3oH+cTfXmfXgR7uuGqO5pmPcGP5eh4YGubCX77I+eW5fO1ic/QDZNw4NLQmoi6QCEePvIiISExJT0ng9qvnUJiezOcf3sS2+g6nS5Jxsm5PG519Q5ynYTUSgRTkRURERiHbm8QdV88hPTmB/+/vm9jbqose48Gq6iZSEtycNsnvdCkib6EgLyIiMkqFGSncfvUchgMBPv/QJtp6BpwuScIoEAiwenszp5dlkZI4/tNcixyNgryIiMgxKMv28qPLZ1Hb3st//WMz/YPDRz9IotLW+k4aOvs1W41ELAV5ERGRY3RySSbfuNiwfl8733rSMhwDE0fIWz1T3YTHBWdNyXa6FJEjCsuCUCIiIrHuwun51Lb18ovndlKUkcKnz5nsdEkyxlZVN3NSSSb+1ESnSxE5IvXIi4iIHKcPn1rKFXMLuWfNHh7bXO90OTKG9hzooaa5m3On5jhdisjbUpAXERE5Ti6Xiy8vLmdhaSbfW17J5jpNSxkrnq5qAmDxNI2Pl8ilIC8iInICEjxuvv+emeSkJfHlf2ymqavf6ZJkDKysamJGgY/CjBSnSxF5WwryIiIiJ8jvTeRHl8+irXeQmx/doplsolxdey+b6zrUGy8RT0FeRERkDJh8H1+7qIINte386OlqAprJJmqtqm4G4HwFeYlwmrVGRERkjFw4PZ+qxi7uWbOHGQU+rpxX7HRJchxWVjUxNdfLpGyv06WIvCP1yIuIiIyhT5xVxumTsvjxyu1sq9fFr9Gmpbuf1/a1cb4WgZIooCAvIiIyhjxuF996lyErNZH//udWOvsGnS5JjsEz1c0MB2BxhYK8RD4FeRERkTGW5U3ie++ZQV1HH9/8t9V4+SjydFUTJf4UynPTnC5F5KgU5EVERMJg3oRMPnPOZFZVN/PXdfucLkdGoaN3kFd2t7J4Wi4ul8vpckSOSkFeREQkTK5ZMIHzpubw89U72FDb7nQ5chTP1jQzNBzQbDUSNRTkRUREwsTlcvH1iw0F6cnc8thWOno1Xj6SraxqIt+XxMzCdKdLERkVBXkREZEwSk9J4Lvvnk5DRx8/eKpK4+UjVHf/EC/uPMD503Jxa1iNRAkFeRERkTCbXZTBTWeWscw28viWBqfLkSN4cWcLfYPDGlYjUUVBXkREZBx8+NRSTi7J5H9XVLO3tcfpcmSEpyubyEpN5KQJmU6XIjJqCvIiIiLjwON28a1LDB63i1sf38bg0LDTJUlI3+Awz+9o4bzyHDxuDauR6KEgLyIiMk4KM1L4ytJpbNrfwV0v7Xa6HAl5cUcLXf1DLKnIc7oUkWOiIC8iIjKOlpo8Lp1VwD0v72b93janyxFguW3En5rIgol+p0sROSYJY31CY0wicDdQBiQD37HWPjriPl5gOXCjtXbb2x1jjJkP/BOoCh36S2vt/WNds4iIyHj60uJyXtvXxjf+bbn3Q/NJSxrzP8cySr0DQzxb08wlMwpI0LAaiTLh6JG/Fmi21p4DXALccfhOY8xCYDUwdRTHzAdus9YuCn0pxIuISNTzJnn4+sWG/W29/PyZHU6XE9ee39FCz8AwS42G1Uj0CUeQfwC49bCfR65+kQxcAWwbxTELgHcbY1YbY35njNEKDSIiEhPmTcjk2oUlPLRhPy/ubHG6nLi13DaS7U3k5BLNViPRZ8w/y7PWdgKEQveDwC0j9j8f2j+aY9YAv7XWrjXG/A/wdeBLIx/T50smIcEz1k/lqDweN36/d9wfV8aX2jk+qJ3jQ6S1883vmsGLu1r57vIqHv/M2WSkJjpdUkwYbTt39Q3y/I4Wrp5fQk522jhUJmMp0l7PTgjLoDxjTCnwMHCntfbeEzjmYWtt68HbwO1HOrazs+8EKz4+fr+X1tZuRx5bxo/aOT6oneNDJLbzrRdO4yP3rudrj2zkG5dMd7qcmDDadl62rYHegWHOLcuKuN8LOTonXs95eZE1OGTMh9YYYwqAZcDN1tq7T/CYJ40xp4ZuXwCsHdNiRUREHDazMJ3rT5vIY1saeKa6yely4spy20ieL4l5EzKcLkXkuISjR/6rQBZwqzHm4Lj3u4A0a+1vjuGYS4BPAncYY/qBOuCmMNQrIiLiqBtPn8iz25v53vIq5hVn4vdqiE24dfYN8sKOFq6cV4zbpdlqJDq5AoGA0zWcsMbGDkeeRCR+RCtjT+0cH9TO8SGS27m6sYvr/ryOReU5fP/SmU6XE9VG086Pb6nn609YfvfBk5hbrB75aOTQ0JqIetenBaFEREQiQHleGjedOYmnKpt4urLR6XJi3nLbSEF6MrOLImvMs8ixUJAXERGJENedUsr0fB8/XFFNW8+A0+XErI7eQV7aeYAlFXkaViNRTUFeREQkQiS4XdxyUQVtPQP89Jkap8uJWSurmhgcDrB0uhaBkuimIC8iIhJBTL6PD51aymOb67VQVJg8sbWeiVmpzCzwOV2KyAlRkBcREYkwN54+ibLsVL63rIqu/pELpMuJqGvvZe2eNi6ZkY9Lw2okyinIi4iIRJjkBDe3XFhBfUcfv3xup9PlxJQntzUSAC6eke90KSInTEFeREQkAs2bkMn7Ty7mb+treX1fm9PlxIRAIMDjW+qZW5xBiT/V6XJETpiCvIiISIT61NmTKcxI5ttPVtI3OOx0OVGvqrGLmuZuLlFvvMQIBXkREZEI5U3y8NWl09h1oIffvbTL6XKi3hNbG/C4XSwxmq1GYoOCvIiISAQ7vSybS2cV8Mc1e7D1nU6XE7WGhgM8ua2BsyZn409NdLockTGhIC8iIhLhPr9oCn5vEt9eVsngkIbYHI9X97TS2NmvYTUSUxTkRUREIlxGSiJfXjwV29DJX9buc7qcqPTE1gbSkjycPSXb6VJExoyCvIiISBRYXJHH+dNyuevFXexq6Xa6nKjS3T/EysomLqjIJSXR43Q5ImNGQV5ERCRKfHnxVJI8br67vIrhQMDpcqLGispGugeGuHRWodOliIwpBXkREZEoketL5nPnTWb93jYe2bDf6XKixqOb6piUlcq8CRlOlyIyphTkRUREoshlswtZONHPz1fvoKGjz+lyIt6ulm5e29fOZbMLcblcTpcjMqYU5EVERKKIy+Xif5ZOY3A4wA+eqiKgITbv6NFN9Xhc8K5ZBU6XIjLmFORFRESiTIk/lU+cVcazNS0st41OlxOxBocDPLalnrOm5JCbluR0OSJjTkFeREQkCv3H/AnMKPDx46e309oz4HQ5EemFHS00d/Vz2Wz1xktsUpAXERGJQgluF7deVEF73yD/t2q70+VEpH9uqiPbm8hZkzV3vMQmBXkREZEoNS3Px4dPKeGxLQ28uLPF6XIiSmNnH8/WtPCeWQUkeBR3JDbpN1tERCSKfeT0SUzKSuV7y6ro7h9yupyI8ciGOoaHA1wxt8jpUkTCRkFeREQkiiUnuLnlwgrqOvq487kdTpcTEQaGhnl4437OmJxFiT/V6XJEwkZBXkREJMqdVJLJ+04q5m/ra9lQ2+50OY5bsa2Bxs5+rp5X7HQpImGVMNYnNMYkAncDZUAy8B1r7aMj7uMFlgM3Wmu3vd0xxphy4B4gAGwCPm2tHR7rmkVERKLdp88pY/X2Zr6zrJI/XzufpIT47av7y8u7KcpI5kxd5CoxLhyv8muBZmvtOcAlwB2H7zTGLARWA1NHccxtwC2h7S7g8jDUKyIiEvXSkhL4ypJp7Gju5p41u50uxzE7mrt5aUcLV80rxuPWSq4S28IR5B8Abj3s58ER+5OBK4BtozhmAfBM6PYTwJKxK1NERCS2nDUlm4um5/H7l/dQ3dTldDmO+PvrtSR6XJo7XuLCmA+tsdZ2Ahhj0oEHgVtG7H8+tH80x7istQfXnu4AMo/0mD5fMgkJnrF7EqPk8bjx+73j/rgyvtTO8UHtHB/ioZ2/+d45rPn5s/xgRTX3f+z0uOqV7uwb5LEtDbx7ThGTi/1OlyNhFg+v56MZ8yAPYIwpBR4G7rTW3nsCxxw+Hj4daD3SsZ2dfSdQ7fHz+720tnY78tgyftTO8UHtHB/ioZ09wBcWTeXWx7fx65VV/L8FJU6XNG7uXbuXzr5BrjttUsy3szjzes7LSx/XxzuaMR9aY4wpAJYBN1tr7z7BY9YbYxaFbl8CPDuWtYqIiMSii6bncdbkbH753E72tfU4Xc64GBwOcN+6fZw8IYO5JUf8AF8k5oRjjPxXgSzgVmPMqtDXNcaYm47xmFTgi8A3jTEvAkkEh92IiIjIO3C5XPz3knLcLhffW1ZFIBA4+kFR7unKRva393HNwvj5BELEFQsv7sbGDkeeRDx8RCtq53ihdo4P8dbOf1tfy4+eruZrF1Vw6exCp8sJm0AgwPX3vkZn3yAP3LCQ7Ky0uGrneOXQ0JqIuugkfieZFRERiXFXn1TEvOIM/u+ZGpq6+p0uJ2zW72tjS10H/2/BBNyuiMpZImGlIC8iIhKj3C4Xt1xYQe/AEN9bVhmzQ2x+//Ie/KmJvHumppyU+KIgLyIiEsPKcrx8+pzJPFvTwj821jldzpjbvL+dl3Ye4JoFE0hJHP+pqEWcpCAvIiIS4/5j/gQWlmby01U17G2NrVlsfvfSbjJSEnjfycVOlyIy7hTkRUREYpzb5eLrFxtcLvjGE5ah4dgYYmMbOnm2poUPzp9AWlJYlsYRiWgK8iIiInGgMCOFL19Qzuu17fzplT1OlzMm7n5pN2lJHj5w8gSnSxFxhIK8iIhInLhkRj4XVOTy6xd2YRs6nS7nhGyp6+DpqiY+OH8C6SnqjZf4pCAvIiISJ4ILRU3Dn5rILY9tpWdgyOmSjksgEOD2Z3fgT03UAlAS1xTkRURE4og/NZFvvcuwq6WHH66odrqc4/LyrgO8uruVj5w+EV+yeuMlfinIi4iIxJlTJmZx4+kTeWxzPf/aHF1TUg4HAtzx7E6KM5K5am6R0+WI/P/t3XlwVeUZx/HvzUYCBBIhgBgWMfCwuDVScEFBkIJ1FKXjMh1xqrUuo61aLSrK0Do6lnEbxVKVDuMyMrWgtIhVUAd3HSpFECUPEAQtwkDCIglLSLj94wYNSVCT3NyTe+7v8xfnzeGcJ/Obe+9z37znnECpkRcREUlBV5/Wh+LCzkx/Yx0byhP7mPuWeG31VnxrBdeN6EtWhtoYSW16BYiIiKSg9LQI9543kOzMdO5Y+Dn7kmC9fMX+ah59ez1DeuQybmC3oMsRCZwaeRERkRRV0LEdfzrXWF+2h/teX0s02rbvL//E+xvYsecAt59TRFokEnQ5IoFTIy8iIpLCTj/2KK49ow+vrd7K88s2BV3OEa3ZWsHcT75m4klHM6h7btDliLQJauRFRERS3FXDezO6f1dmvLOejzZsD7qcBqoPRvnzG2vplJ3J9Wf0DbockTZDjbyIiEiKi0QiTBtv9OvSgbteKeHLHXuDLukwz/3nKz7dvJtbzz6OzjmZQZcj0maokRcRERHaZ6XzwITBpEUi/O7FTymvrAq6JCC2pOapDzZyzoCujBtYEHQ5Im2KGnkREREBoDAvh0cuGkJ5ZRU3v7SKyqrqQOupqj7ItFedzjmZ3D6mPxFd4CpyGDXyIiIi8q3jj+7E/ecPYu22Cu5YsJoDNQcDq+WhJaWsK6vk7p/1J6+9ltSI1KdGXkRERA4zol8XpowdwEcbd3DXKyVUB9DML1i1hZdWbuaKn/ZiRL8uCT+/SDJQIy8iIiINXHBCD24Z1Y8la8u4c2FiZ+ZXbNrF9DfWMrR3HteP6Juw84okGzXyIiIi0qhfnlLIrWcfx1vrypm8IDFPf/2ifA+//+dn9OiUzf3nDSIjTeviRY5EjbyIiIgc0WXFxzB5TBHvr9/Otf9Y2ap3s9m4fQ83zltJRlqERycer3XxIj9AjbyIiIh8r4tP7skDEwZTWlbJVXOW41sr4n6O0rJKrnlhBQdqosz4xQkU5uXE/RwiYZMR7wOaWSYwG+gLtAPudfcF9fZpD7wO/NrdS+qMDwemu/uo2u1i4GVgbe0uf3X3F+Jds4iIiHy/kUVdefLSk/jDvz7jyjnLuemsflzyk55xuSXku6XlTP13CTmZ6cy85ESO7dI+DhWLhF/cG3ngcqDc3SeZWRdgOfBtI29mQ4EngMK6/8nMJgOTgMo6w8XAw+7+UCvUKSIiIk0wpEcuz08q5p5Fa3hwSSnvfbGdyaOL6JXfvNnz/dUHmfXhRp5d+hXWrSMPTBhMj07Zca5aJLxao5GfC8yrs13/aRLtgIuA5+qNlwIT642fApiZTSA2K3+zu++Ob7kiIiLyY+W3z+LhC4cw95OvmfneBi595mMuPrknk4YW0rVjux91jGg0yjul25nxzno27tjLhON7cNvo48jOTG/l6kXCJRKNRlvlwGaWS2wmfpa7z2nk528B19VbWtMX+Lu7n1q7fSWw0t2XmdldQL6731b/WHv3VkUzMhL/4k9PT6MmwAdlSGIo59SgnFODco6vrbv38eDra1iwYjPpaRHGDuzG+Sf2ZNix+eRmN7xQdfOufSz+fAvz/ruJki276X1Ue/54/mDOLOoa17qUc2oIIufMzPQ2dRul1piRx8x6AfOBmY018U0w3913Hvo3MKOxnSoq9rfgFM2Xl9eenTv3BHJuSRzlnBqUc2pQzvGVBUwZXcQVxccwZ9kmFpds5ZVVW4gAvfNzKOiYRbuMdPYcqOGrHXspq73jTf+CDkwbP4Dxg7qTkRaJeybKOTUEkXNBQW5Cz/dDWuNi1+7AYuBGd3+zhYdbZGa/dfelwBhgWYsLFBERkbgqzMth8pgibhnVj3MivN4AAAQWSURBVOX/28WKTd+wtqyS7ZVVVOyvIicrnWF98rBuHTmt71G6mFUkTlpjRn4KkA9MNbOptWOzgA7u/lQTj3U98LiZVQFbgGviV6aIiIjEU2Z6GsP65DOsT37QpYikhFZbI59I27btDuSX0J/uUoNyTg3KOTUo59SgnFNDQEtr2tQaeT0QSkREREQkCamRFxERERFJQmrkRURERESSkBp5EREREZEkpEZeRERERCQJqZEXEREREUlCauRFRERERJKQGnkRERERkSQUigdCiYiIiIikGs3Ii4iIiIgkITXyIiIiIiJJSI28iIiIiEgSygi6gGRkZmnATOAkYD9wtbuvC7YqaS4zywRmA32BdsC9wOfA00AUWAXc4O4HzWwacB5QDdzs7kuDqFmaz8y6AcuAscRyfBrlHCpmdidwAZBF7L36bZRzqNS+bz9D7H27BvgNej2HipkNB6a7+ygzK+JHZnukfYP4HRJBM/LNcyGQ7e6nAXcADwVcj7TM5UC5u58JnAs8DjwM3F07FgEmmFkxMBIYDlwG/CWgeqWZaj/8nwT21g4p55Axs1HA6cAZxHLshXIOo58DGe5+OnAPcB/KOTTMbDLwNyC7dqgp2TbYN5G1J5oa+eYZAbwG4O4fAUODLUdaaC4wtc52NXAKsVk8gFeBc4jlvtjdo+7+JZBhZgUJrVRa6kHgCeDr2m3lHD7jgE+B+cDLwEKUcxitIZZZGtAJOIByDpNSYGKd7aZk29i+oaVGvnk6AbvqbNeYmZYpJSl3r3D33WaWC8wD7gYi7n7o3qy7gc40zP3QuCQBM/sVsM3dF9UZVs7h05XY5MrFwHXA80Cacg6dCmLLakqAWcBj6PUcGu7+IrEvZ4c0JdvG9g0tNfLN8w2QW2c7zd2rgypGWs7MegFLgOfcfQ5Qdz1dLrCThrkfGpfkcBUw1szeAk4GngW61fm5cg6HcmCRu1e5uwP7OPyDXDmHwy3Ech5A7Hq1Z4hdE3GIcg6XpnwmN7ZvaKmRb573ia3Pw8xOJfZnXElSZtYdWAzc7u6za4eX1661hdi6+XeJ5T7OzNLMrDexL3BlCS9YmsXdz3L3ke4+CvgEuAJ4VTmHznvAeDOLmFlPoAPwpnIOnR18Nxu7HchE79th1pRsG9s3tLQcpHnmE5vZ+4DYhRRXBlyPtMwUIB+YamaH1srfBDxmZlnAamCeu9eY2bvAh8S+BN8QSLUST7cCs5RzeLj7QjM7C1jKd/l9gXIOm0eA2bUZZhF7H/8Y5RxWTXmvbrBvEAUnSiQajf7wXiIiIiIi0qZoaY2IiIiISBJSIy8iIiIikoTUyIuIiIiIJCE18iIiIiIiSUiNvIiIiIhIElIjLyIiIiKShNTIi4iIiIgkITXyIiIiIiJJ6P/7AEjkG9rTngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(n_epochs)]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(12,10))\n",
    "\n",
    "for model_ in models:\n",
    "    name = model_[0]\n",
    "    training_loss = model_[1]\n",
    "    valid_loss =model_[2] \n",
    "\n",
    "    \n",
    "    label = name \n",
    "    \n",
    "    ax[0].plot(x,  training_loss, label=label)\n",
    "    ax[1].plot(x,  valid_loss, label=label)\n",
    "    #ax[2].plot([i for i in range(n_epochs-1)],  valid_loss[1:] / valid_loss[:-1] * 100, label=label)\n",
    "\n",
    "\n",
    "#ax[2].set_xlabel('epoch') \n",
    "\n",
    "ax[0].set_ylabel('loss') \n",
    "ax[1].set_ylabel('loss')\n",
    "\n",
    "ax[0].set_title(\"training loss\")\n",
    "ax[1].set_title(\"validation loss\")\n",
    "#ax[2].set_title(\"validation loss change in %\")\n",
    "\n",
    "legend  = ax[0].legend(bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "#ax[2].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serializing best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# # Serializing model \n",
    "# =============================================================================\n",
    "\n",
    "wdir= r'C:/Users/hauer/Documents/Repositories/cfds_project'\n",
    "save_dir = os.path.join(wdir, 'pytorch_models')\n",
    "model_name = 'rnn.torch'\n",
    "\n",
    "if(not os.path.isdir(save_dir)):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "save(model.state_dict(), os.path.join(save_dir, model_name))\n",
    "\n",
    "#model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "#model.load_state_dict(load( os.path.join(save_dir, model_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01369219, 0.00042881, 0.00120457, 0.06186881, 0.01417604,\n",
       "       0.01045175], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country = 'Germany'\n",
    "\n",
    "df = database_training_sv_standard[country].append(database_validation_sv_standard[country])\n",
    "\n",
    "n_forecast_validation, _ = database_validation_sv_standard[country].shape\n",
    "\n",
    "X_eval = df.iloc[:,1:].values\n",
    "y_eval = df.iloc[:,0].values\n",
    "X_eval_T = from_numpy(X_eval).float()\n",
    "N, _ = X_eval_T.shape\n",
    "X_eval_T = X_eval_T.view([-1, N, dummy_dim])\n",
    "\n",
    "hidden_1 = zeros(1, N, hidden_dim)\n",
    "state_1 = zeros(1, N, hidden_dim)\n",
    "\n",
    "hidden_2 = zeros(1, N, hidden_dim)\n",
    "state_2 = zeros(1, N, hidden_dim)\n",
    "\n",
    "model.eval()\n",
    "with no_grad():\n",
    "    y_hat = model(X_eval_T, hidden_1, state_1, hidden_2, state_2)\n",
    "    \n",
    "y_hat =  y_hat.view(-1).numpy()\n",
    "y_forecast = y_hat[-n_forecast_validation:]\n",
    "y_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with the ground truth.\n",
    "\n",
    "First check right application of scaling. The unscaled data must equal the scaled data after appling the inverse_transform method from sklearn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>GHG</th>\n",
       "      <th>Current account balance</th>\n",
       "      <th>General government net lending/borrowing</th>\n",
       "      <th>PPP</th>\n",
       "      <th>Inflation, average consumer prices</th>\n",
       "      <th>ExchangeR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>2.051359</td>\n",
       "      <td>0.661859</td>\n",
       "      <td>1.852348</td>\n",
       "      <td>-0.058174</td>\n",
       "      <td>0.654957</td>\n",
       "      <td>1.051777</td>\n",
       "      <td>0.547797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>2.518101</td>\n",
       "      <td>0.640522</td>\n",
       "      <td>1.845025</td>\n",
       "      <td>-1.246360</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>1.167132</td>\n",
       "      <td>0.503668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>2.072474</td>\n",
       "      <td>0.661971</td>\n",
       "      <td>1.786614</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0.658295</td>\n",
       "      <td>1.140200</td>\n",
       "      <td>0.513078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2.013436</td>\n",
       "      <td>0.617975</td>\n",
       "      <td>1.818870</td>\n",
       "      <td>3.318150</td>\n",
       "      <td>0.662904</td>\n",
       "      <td>0.706676</td>\n",
       "      <td>0.583932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.690894</td>\n",
       "      <td>1.812187</td>\n",
       "      <td>0.607133</td>\n",
       "      <td>0.665526</td>\n",
       "      <td>1.869612</td>\n",
       "      <td>0.582607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1.860920</td>\n",
       "      <td>0.634447</td>\n",
       "      <td>1.827969</td>\n",
       "      <td>-0.435978</td>\n",
       "      <td>0.659129</td>\n",
       "      <td>1.428403</td>\n",
       "      <td>0.525331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y       GHG  Current account balance  \\\n",
       "2005  2.051359  0.661859                 1.852348   \n",
       "2006  2.518101  0.640522                 1.845025   \n",
       "2007  2.072474  0.661971                 1.786614   \n",
       "2008  2.013436  0.617975                 1.818870   \n",
       "2009  0.234375  0.690894                 1.812187   \n",
       "2010  1.860920  0.634447                 1.827969   \n",
       "\n",
       "      General government net lending/borrowing       PPP  \\\n",
       "2005                                 -0.058174  0.654957   \n",
       "2006                                 -1.246360  0.662903   \n",
       "2007                                 -6.907755  0.658295   \n",
       "2008                                  3.318150  0.662904   \n",
       "2009                                  0.607133  0.665526   \n",
       "2010                                 -0.435978  0.659129   \n",
       "\n",
       "      Inflation, average consumer prices  ExchangeR  \n",
       "2005                            1.051777   0.547797  \n",
       "2006                            1.167132   0.503668  \n",
       "2007                            1.140200   0.513078  \n",
       "2008                            0.706676   0.583932  \n",
       "2009                            1.869612   0.582607  \n",
       "2010                            1.428403   0.525331  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = database_scaler[country]\n",
    "\n",
    "database_validation_sv[country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.051359</td>\n",
       "      <td>0.661859</td>\n",
       "      <td>1.852348</td>\n",
       "      <td>-0.058174</td>\n",
       "      <td>0.654957</td>\n",
       "      <td>1.051777</td>\n",
       "      <td>0.547797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.518101</td>\n",
       "      <td>0.640522</td>\n",
       "      <td>1.845025</td>\n",
       "      <td>-1.246360</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>1.167132</td>\n",
       "      <td>0.503668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.072474</td>\n",
       "      <td>0.661971</td>\n",
       "      <td>1.786614</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0.658295</td>\n",
       "      <td>1.140200</td>\n",
       "      <td>0.513078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.013436</td>\n",
       "      <td>0.617975</td>\n",
       "      <td>1.818870</td>\n",
       "      <td>3.318150</td>\n",
       "      <td>0.662904</td>\n",
       "      <td>0.706676</td>\n",
       "      <td>0.583932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.690894</td>\n",
       "      <td>1.812187</td>\n",
       "      <td>0.607133</td>\n",
       "      <td>0.665526</td>\n",
       "      <td>1.869612</td>\n",
       "      <td>0.582607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.860920</td>\n",
       "      <td>0.634447</td>\n",
       "      <td>1.827969</td>\n",
       "      <td>-0.435978</td>\n",
       "      <td>0.659129</td>\n",
       "      <td>1.428403</td>\n",
       "      <td>0.525331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  2.051359  0.661859  1.852348 -0.058174  0.654957  1.051777  0.547797\n",
       "1  2.518101  0.640522  1.845025 -1.246360  0.662903  1.167132  0.503668\n",
       "2  2.072474  0.661971  1.786614 -6.907755  0.658295  1.140200  0.513078\n",
       "3  2.013436  0.617975  1.818870  3.318150  0.662904  0.706676  0.583932\n",
       "4  0.234375  0.690894  1.812187  0.607133  0.665526  1.869612  0.582607\n",
       "5  1.860920  0.634447  1.827969 -0.435978  0.659129  1.428403  0.525331"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scaler.inverse_transform(database_validation_sv_standard[country]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the output back to original scale: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = database_validation_sv_standard[country]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwriting the forecast to the dataframe in order to call the inverse_transform method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.977376</td>\n",
       "      <td>0.233201</td>\n",
       "      <td>-1.540170</td>\n",
       "      <td>-1.811933</td>\n",
       "      <td>0.173565</td>\n",
       "      <td>0.031546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000429</td>\n",
       "      <td>-0.824086</td>\n",
       "      <td>0.229011</td>\n",
       "      <td>-5.745871</td>\n",
       "      <td>-0.464783</td>\n",
       "      <td>0.244783</td>\n",
       "      <td>-0.691070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.986829</td>\n",
       "      <td>0.195587</td>\n",
       "      <td>-25.784944</td>\n",
       "      <td>-1.245999</td>\n",
       "      <td>0.228155</td>\n",
       "      <td>-0.536981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061869</td>\n",
       "      <td>-2.727739</td>\n",
       "      <td>0.214045</td>\n",
       "      <td>10.410665</td>\n",
       "      <td>-0.464502</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>0.623240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014176</td>\n",
       "      <td>3.428772</td>\n",
       "      <td>0.210220</td>\n",
       "      <td>0.814749</td>\n",
       "      <td>-0.020067</td>\n",
       "      <td>0.678478</td>\n",
       "      <td>0.601555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010452</td>\n",
       "      <td>-1.337028</td>\n",
       "      <td>0.219251</td>\n",
       "      <td>-2.877446</td>\n",
       "      <td>-1.104656</td>\n",
       "      <td>0.406086</td>\n",
       "      <td>-0.336342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2          3         4         5         6\n",
       "0  0.013692  0.977376  0.233201  -1.540170 -1.811933  0.173565  0.031546\n",
       "1  0.000429 -0.824086  0.229011  -5.745871 -0.464783  0.244783 -0.691070\n",
       "2  0.001205  0.986829  0.195587 -25.784944 -1.245999  0.228155 -0.536981\n",
       "3  0.061869 -2.727739  0.214045  10.410665 -0.464502 -0.039492  0.623240\n",
       "4  0.014176  3.428772  0.210220   0.814749 -0.020067  0.678478  0.601555\n",
       "5  0.010452 -1.337028  0.219251  -2.877446 -1.104656  0.406086 -0.336342"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.iloc[:,0] = y_forecast\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.691698</td>\n",
       "      <td>0.661859</td>\n",
       "      <td>1.852348</td>\n",
       "      <td>-0.058174</td>\n",
       "      <td>0.654957</td>\n",
       "      <td>1.051777</td>\n",
       "      <td>0.547797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.667858</td>\n",
       "      <td>0.640522</td>\n",
       "      <td>1.845025</td>\n",
       "      <td>-1.246360</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>1.167132</td>\n",
       "      <td>0.503668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.669252</td>\n",
       "      <td>0.661971</td>\n",
       "      <td>1.786614</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0.658295</td>\n",
       "      <td>1.140200</td>\n",
       "      <td>0.513078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.778293</td>\n",
       "      <td>0.617975</td>\n",
       "      <td>1.818870</td>\n",
       "      <td>3.318150</td>\n",
       "      <td>0.662904</td>\n",
       "      <td>0.706676</td>\n",
       "      <td>0.583932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.692568</td>\n",
       "      <td>0.690894</td>\n",
       "      <td>1.812187</td>\n",
       "      <td>0.607133</td>\n",
       "      <td>0.665526</td>\n",
       "      <td>1.869612</td>\n",
       "      <td>0.582607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.685873</td>\n",
       "      <td>0.634447</td>\n",
       "      <td>1.827969</td>\n",
       "      <td>-0.435978</td>\n",
       "      <td>0.659129</td>\n",
       "      <td>1.428403</td>\n",
       "      <td>0.525331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  1.691698  0.661859  1.852348 -0.058174  0.654957  1.051777  0.547797\n",
       "1  1.667858  0.640522  1.845025 -1.246360  0.662903  1.167132  0.503668\n",
       "2  1.669252  0.661971  1.786614 -6.907755  0.658295  1.140200  0.513078\n",
       "3  1.778293  0.617975  1.818870  3.318150  0.662904  0.706676  0.583932\n",
       "4  1.692568  0.690894  1.812187  0.607133  0.665526  1.869612  0.582607\n",
       "5  1.685873  0.634447  1.827969 -0.435978  0.659129  1.428403  0.525331"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output = pd.DataFrame(scaler.inverse_transform(df_output))\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69169797, 1.66785757, 1.66925199, 1.7782935 , 1.69256768,\n",
       "       1.6858734 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_forecast = df_output.iloc[:,0].values\n",
    "y_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.05135894, 2.51810131, 2.07247393, 2.01343609, 0.23437483,\n",
       "       1.86092044])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_validation_sv[country].iloc[:,0].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
