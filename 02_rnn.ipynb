{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hauer\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "C:\\Users\\hauer\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for printing the definition of custom functions\n",
    "import inspect\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "# pytorch\n",
    "from torch import nn, no_grad, save, load\n",
    "from torch import from_numpy, zeros\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-dark')\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_dir = os.path.join(r'C:/Users/hauer/Documents/Repositories/cfds_project', 'database.pickle')\n",
    "\n",
    "with open(database_dir,'rb') as f: \n",
    "    db = pickle.load(f)\n",
    "    \n",
    "database_training = db['database_training']\n",
    "database_validation = db['database_validation']\n",
    "database_test = db['database_test']\n",
    "\n",
    "database_training_sv = db['database_training_sv']\n",
    "database_validation_sv = db['database_validation_sv']\n",
    "database_test_sv = db['database_test_sv']\n",
    "\n",
    "database_training_sv_standard = db['database_training_sv_standard']\n",
    "database_validation_sv_standard = db['database_validation_sv_standard']\n",
    "database_test_sv_standard = db['database_test_sv_standard']\n",
    "\n",
    "database_scaler = db['database_scaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RNN start\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# # Prepare Data for RNN\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# Combining orignal training and \n",
    "database_training = {}\n",
    "\n",
    "for country in database_training_sv_standard.keys():\n",
    "    df_to_add = database_training_sv_standard[country].append(database_validation_sv_standard[country])\n",
    "    df_to_add = df_to_add.reset_index()\n",
    "    del df_to_add['index']\n",
    "\n",
    "    database_training[country] = df_to_add\n",
    "\n",
    "\n",
    "N, dummy_dim = database_training['Germany'].shape\n",
    "dummy_dim -= 1\n",
    "\n",
    "time_steps = 16\n",
    "horizon = 1\n",
    "sequence_length = time_steps + horizon \n",
    "\n",
    "\n",
    "max_index = N - sequence_length + 1\n",
    "\n",
    "number_of_countries = len(database_training.keys())\n",
    "\n",
    "X = np.empty([0, sequence_length,dummy_dim])\n",
    "y = np.empty([0, sequence_length])\n",
    "\n",
    " \n",
    "\n",
    "for country in database_training.keys():\n",
    "    df_training_current = database_training[country]\n",
    "\n",
    "    X_current = np.empty([max_index, sequence_length,dummy_dim])\n",
    "    y_current = np.empty([max_index, sequence_length])\n",
    "\n",
    "    for i in range(max_index):\n",
    "\n",
    "        X_current[i] = df_training_current.iloc[i:i+sequence_length,1:].values\n",
    "        y_current[i] = df_training_current.iloc[i:i+sequence_length,0].values\n",
    "        \n",
    "    X = np.concatenate((X, X_current))\n",
    "    y = np.concatenate((y, y_current))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "N, seq_len, dummy_dim = X.shape\n",
    "\n",
    "input_size=dummy_dim\n",
    "n_layers=1\n",
    "output_size=1\n",
    "test_size = 0.20\n",
    "batch_size = 25\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=123)\n",
    "\n",
    "\n",
    "X_train_T = from_numpy(X_train).float()\n",
    "y_train_T = from_numpy(y_train).float()\n",
    "X_val_T = from_numpy(X_val).float()\n",
    "y_val_T = from_numpy(y_val).float()\n",
    "\n",
    "train_ds = TensorDataset(X_train_T, y_train_T)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)  \n",
    "\n",
    "valid_ds = TensorDataset(X_val_T, y_val_T)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)\n",
    "\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 136.5 valid loss: 4.686\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "    \n",
    "name = 'RNN'\n",
    "hidden_dim=3\n",
    "lr = 0.03\n",
    "\n",
    "model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = SGD(model.parameters(), lr = lr)  \n",
    "\n",
    "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_0)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_0)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))   \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 140.7 valid loss: 5.433\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "    \n",
    "name = 'RNN_Adam'\n",
    "hidden_dim=3\n",
    "lr = 1e-06\n",
    "\n",
    "model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    " \n",
    "\n",
    "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_0)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_0)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))   \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 136.5 valid loss: 4.687\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "    \n",
    "name = 'RNN_Large_Adam'\n",
    "hidden_dim=64\n",
    "lr = 1e-06\n",
    "\n",
    "model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    " \n",
    "\n",
    "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_0)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_0)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))   \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 135.6 valid loss: 4.594\n"
     ]
    }
   ],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(LSTMNet, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "               \n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, state):\n",
    "        r_out, (hidden_out, state_out) = self.lstm1(x, (hidden, state))\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = 'LSTM'\n",
    "hidden_dim=10\n",
    "lr = 0.03\n",
    "\n",
    "model = LSTMNet(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = SGD(model.parameters(), lr = lr)  \n",
    "\n",
    "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
    "state_0 = zeros(1, seq_len, hidden_dim)\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "\n",
    "    \n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_0, state_0)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_0, state_0)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))  \n",
    "        \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Adam Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 135.6 valid loss: 4.582\n"
     ]
    }
   ],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(LSTMNet, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "               \n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, state):\n",
    "        r_out, (hidden_out, state_out) = self.lstm1(x, (hidden, state))\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = 'LSTM_Large_Adam'\n",
    "hidden_dim=64\n",
    "lr = 1e-06\n",
    "\n",
    "model = LSTMNet(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "hidden_0 = zeros(1, seq_len, hidden_dim)\n",
    "state_0 = zeros(1, seq_len, hidden_dim)\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "\n",
    "    \n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_0, state_0)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_0, state_0)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {}: train loss: {:.4} valid loss: {:.4}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))  \n",
    "        \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 135.52339 valid loss: 4.5823107\n"
     ]
    }
   ],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, output_size, hidden_dim, n_layers):\n",
    "        super(LSTMNet, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "               \n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_dim)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden_1, state_1, hidden_2, state_2):\n",
    "        r_out, (hidden_out, state_out) = self.lstm1(x, (hidden_1, state_1))      \n",
    "        r_out, (hidden_out, state_out) = self.lstm2(r_out, (hidden_2, state_2))\n",
    "        r_out = self.fc(r_out)\n",
    "        \n",
    "        return r_out\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return zeros(1, self.seq_len, self.hidden_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = 'LSTM_Stacked'\n",
    "hidden_dim=64\n",
    "lr = 0.05\n",
    "\n",
    "model = LSTMNet(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "optimizer = SGD(model.parameters(), lr = lr)  \n",
    "\n",
    "hidden_01 = zeros(1, seq_len, hidden_dim)\n",
    "state_01 = zeros(1, seq_len, hidden_dim)\n",
    "\n",
    "hidden_02 = zeros(1, seq_len, hidden_dim)\n",
    "state_02 = zeros(1, seq_len, hidden_dim)\n",
    "\n",
    "training_losses = np.empty(n_epochs)\n",
    "valid_losses = np.empty(n_epochs)\n",
    "\n",
    "\n",
    "    \n",
    "# =============================================================================\n",
    "# # Training loop \n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch, hidden_01, state_01, hidden_02, state_02)\n",
    "        \n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with no_grad():\n",
    "        for X_batch, y_batch in valid_dl:\n",
    "            y_pred = model(X_batch, hidden_01, state_01, hidden_02, state_02)\n",
    "            loss = loss_func(y_pred.squeeze(), y_batch.squeeze()) \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    training_loss_epoch = training_loss \n",
    "    valid_loss_epoch = valid_loss \n",
    "    \n",
    "    training_losses[epoch] = training_loss_epoch\n",
    "    valid_losses[epoch] = valid_loss_epoch\n",
    "    \n",
    "    if epoch % 25 == 0:\n",
    "        print('Epoch {}: train loss: {:.8} valid loss: {:.8}'\n",
    "              .format(epoch, training_loss_epoch, valid_loss_epoch))  \n",
    "        \n",
    "        \n",
    "models.append( (name, training_losses, valid_losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(n_epochs)]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(12,10))\n",
    "\n",
    "for model_ in models:\n",
    "    name = model_[0]\n",
    "    training_loss = model_[1]\n",
    "    valid_loss =model_[2] \n",
    "\n",
    "    \n",
    "    label = name \n",
    "    \n",
    "    ax[0].plot(x,  training_loss, label=label)\n",
    "    ax[1].plot(x,  valid_loss, label=label)\n",
    "    #ax[2].plot([i for i in range(n_epochs-1)],  valid_loss[1:] / valid_loss[:-1] * 100, label=label)\n",
    "\n",
    "\n",
    "#ax[2].set_xlabel('epoch') \n",
    "\n",
    "ax[0].set_ylabel('loss') \n",
    "ax[1].set_ylabel('loss')\n",
    "\n",
    "ax[0].set_title(\"training loss\")\n",
    "ax[1].set_title(\"validation loss\")\n",
    "#ax[2].set_title(\"validation loss change in %\")\n",
    "\n",
    "legend  = ax[0].legend(bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "#ax[2].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serializing best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# # Serializing model \n",
    "# =============================================================================\n",
    "\n",
    "wdir= r'C:/Users/hauer/Documents/Repositories/cfds_project'\n",
    "save_dir = os.path.join(wdir, 'pytorch_models')\n",
    "model_name = 'rnn.torch'\n",
    "\n",
    "if(not os.path.isdir(save_dir)):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "save(model.state_dict(), os.path.join(save_dir, model_name))\n",
    "\n",
    "#model = RNN(input_size, seq_len, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "#model.load_state_dict(load( os.path.join(save_dir, model_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05118676, -0.04455435, -0.04927543, -0.03331243, -0.0442435 ,\n",
       "       -0.04414071], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country = 'Germany'\n",
    "\n",
    "df = database_training_sv_standard[country].append(database_validation_sv_standard[country])\n",
    "\n",
    "n_forecast_validation, _ = database_validation_sv_standard[country].shape\n",
    "\n",
    "X_eval = df.iloc[:,1:].values\n",
    "y_eval = df.iloc[:,0].values\n",
    "X_eval_T = from_numpy(X_eval).float()\n",
    "N, _ = X_eval_T.shape\n",
    "X_eval_T = X_eval_T.view([-1, N, dummy_dim])\n",
    "\n",
    "hidden_1 = zeros(1, N, hidden_dim)\n",
    "state_1 = zeros(1, N, hidden_dim)\n",
    "\n",
    "hidden_2 = zeros(1, N, hidden_dim)\n",
    "state_2 = zeros(1, N, hidden_dim)\n",
    "\n",
    "model.eval()\n",
    "with no_grad():\n",
    "    y_hat = model(X_eval_T, hidden_1, state_1, hidden_2, state_2)\n",
    "    \n",
    "y_hat =  y_hat.view(-1).numpy()\n",
    "y_forecast = y_hat[-n_forecast_validation:]\n",
    "y_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with the ground truth.\n",
    "\n",
    "First check right application of scaling. The unscaled data must equal the scaled data after appling the inverse_transform method from sklearn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>Inflation, average consumer prices</th>\n",
       "      <th>PPP</th>\n",
       "      <th>Current account balance</th>\n",
       "      <th>GHG</th>\n",
       "      <th>General government net lending/borrowing</th>\n",
       "      <th>ExchangeR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>2.051359</td>\n",
       "      <td>1.051777</td>\n",
       "      <td>0.654957</td>\n",
       "      <td>1.852348</td>\n",
       "      <td>0.661859</td>\n",
       "      <td>-0.058174</td>\n",
       "      <td>0.547797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>2.518101</td>\n",
       "      <td>1.167132</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>1.845025</td>\n",
       "      <td>0.640522</td>\n",
       "      <td>-1.246360</td>\n",
       "      <td>0.503668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>2.072474</td>\n",
       "      <td>1.140200</td>\n",
       "      <td>0.658295</td>\n",
       "      <td>1.786614</td>\n",
       "      <td>0.661971</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0.513078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2.013436</td>\n",
       "      <td>0.706676</td>\n",
       "      <td>0.662904</td>\n",
       "      <td>1.818870</td>\n",
       "      <td>0.617975</td>\n",
       "      <td>3.318150</td>\n",
       "      <td>0.583932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.234375</td>\n",
       "      <td>1.869612</td>\n",
       "      <td>0.665526</td>\n",
       "      <td>1.812187</td>\n",
       "      <td>0.690894</td>\n",
       "      <td>0.607133</td>\n",
       "      <td>0.582607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1.860920</td>\n",
       "      <td>1.428403</td>\n",
       "      <td>0.659129</td>\n",
       "      <td>1.827969</td>\n",
       "      <td>0.634447</td>\n",
       "      <td>-0.435978</td>\n",
       "      <td>0.525331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y  Inflation, average consumer prices       PPP  \\\n",
       "2005  2.051359                            1.051777  0.654957   \n",
       "2006  2.518101                            1.167132  0.662903   \n",
       "2007  2.072474                            1.140200  0.658295   \n",
       "2008  2.013436                            0.706676  0.662904   \n",
       "2009  0.234375                            1.869612  0.665526   \n",
       "2010  1.860920                            1.428403  0.659129   \n",
       "\n",
       "      Current account balance       GHG  \\\n",
       "2005                 1.852348  0.661859   \n",
       "2006                 1.845025  0.640522   \n",
       "2007                 1.786614  0.661971   \n",
       "2008                 1.818870  0.617975   \n",
       "2009                 1.812187  0.690894   \n",
       "2010                 1.827969  0.634447   \n",
       "\n",
       "      General government net lending/borrowing  ExchangeR  \n",
       "2005                                 -0.058174   0.547797  \n",
       "2006                                 -1.246360   0.503668  \n",
       "2007                                 -6.907755   0.513078  \n",
       "2008                                  3.318150   0.583932  \n",
       "2009                                  0.607133   0.582607  \n",
       "2010                                 -0.435978   0.525331  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = database_scaler[country]\n",
    "\n",
    "database_validation_sv[country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.051359</td>\n",
       "      <td>1.051777</td>\n",
       "      <td>0.654957</td>\n",
       "      <td>1.852348</td>\n",
       "      <td>0.661859</td>\n",
       "      <td>-0.058174</td>\n",
       "      <td>0.547797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.518101</td>\n",
       "      <td>1.167132</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>1.845025</td>\n",
       "      <td>0.640522</td>\n",
       "      <td>-1.246360</td>\n",
       "      <td>0.503668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.072474</td>\n",
       "      <td>1.140200</td>\n",
       "      <td>0.658295</td>\n",
       "      <td>1.786614</td>\n",
       "      <td>0.661971</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0.513078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.013436</td>\n",
       "      <td>0.706676</td>\n",
       "      <td>0.662904</td>\n",
       "      <td>1.818870</td>\n",
       "      <td>0.617975</td>\n",
       "      <td>3.318150</td>\n",
       "      <td>0.583932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234375</td>\n",
       "      <td>1.869612</td>\n",
       "      <td>0.665526</td>\n",
       "      <td>1.812187</td>\n",
       "      <td>0.690894</td>\n",
       "      <td>0.607133</td>\n",
       "      <td>0.582607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.860920</td>\n",
       "      <td>1.428403</td>\n",
       "      <td>0.659129</td>\n",
       "      <td>1.827969</td>\n",
       "      <td>0.634447</td>\n",
       "      <td>-0.435978</td>\n",
       "      <td>0.525331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  2.051359  1.051777  0.654957  1.852348  0.661859 -0.058174  0.547797\n",
       "1  2.518101  1.167132  0.662903  1.845025  0.640522 -1.246360  0.503668\n",
       "2  2.072474  1.140200  0.658295  1.786614  0.661971 -6.907755  0.513078\n",
       "3  2.013436  0.706676  0.662904  1.818870  0.617975  3.318150  0.583932\n",
       "4  0.234375  1.869612  0.665526  1.812187  0.690894  0.607133  0.582607\n",
       "5  1.860920  1.428403  0.659129  1.827969  0.634447 -0.435978  0.525331"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scaler.inverse_transform(database_validation_sv_standard[country]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the output back to original scale: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = database_validation_sv_standard[country]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwriting the forecast to the dataframe in order to call the inverse_transform method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.051187</td>\n",
       "      <td>0.173565</td>\n",
       "      <td>-1.811933</td>\n",
       "      <td>0.233201</td>\n",
       "      <td>0.977376</td>\n",
       "      <td>-1.540170</td>\n",
       "      <td>0.031546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.044554</td>\n",
       "      <td>0.244783</td>\n",
       "      <td>-0.464783</td>\n",
       "      <td>0.229011</td>\n",
       "      <td>-0.824086</td>\n",
       "      <td>-5.745871</td>\n",
       "      <td>-0.691070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.049275</td>\n",
       "      <td>0.228155</td>\n",
       "      <td>-1.245999</td>\n",
       "      <td>0.195587</td>\n",
       "      <td>0.986829</td>\n",
       "      <td>-25.784944</td>\n",
       "      <td>-0.536981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.033312</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.464502</td>\n",
       "      <td>0.214045</td>\n",
       "      <td>-2.727739</td>\n",
       "      <td>10.410665</td>\n",
       "      <td>0.623240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.044243</td>\n",
       "      <td>0.678478</td>\n",
       "      <td>-0.020067</td>\n",
       "      <td>0.210220</td>\n",
       "      <td>3.428772</td>\n",
       "      <td>0.814749</td>\n",
       "      <td>0.601555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.044141</td>\n",
       "      <td>0.406086</td>\n",
       "      <td>-1.104656</td>\n",
       "      <td>0.219251</td>\n",
       "      <td>-1.337028</td>\n",
       "      <td>-2.877446</td>\n",
       "      <td>-0.336342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4          5         6\n",
       "0 -0.051187  0.173565 -1.811933  0.233201  0.977376  -1.540170  0.031546\n",
       "1 -0.044554  0.244783 -0.464783  0.229011 -0.824086  -5.745871 -0.691070\n",
       "2 -0.049275  0.228155 -1.245999  0.195587  0.986829 -25.784944 -0.536981\n",
       "3 -0.033312 -0.039492 -0.464502  0.214045 -2.727739  10.410665  0.623240\n",
       "4 -0.044243  0.678478 -0.020067  0.210220  3.428772   0.814749  0.601555\n",
       "5 -0.044141  0.406086 -1.104656  0.219251 -1.337028  -2.877446 -0.336342"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.iloc[:,0] = y_forecast\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.575081</td>\n",
       "      <td>1.051777</td>\n",
       "      <td>0.654957</td>\n",
       "      <td>1.852348</td>\n",
       "      <td>0.661859</td>\n",
       "      <td>-0.058174</td>\n",
       "      <td>0.547797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.587002</td>\n",
       "      <td>1.167132</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>1.845025</td>\n",
       "      <td>0.640522</td>\n",
       "      <td>-1.246360</td>\n",
       "      <td>0.503668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.578516</td>\n",
       "      <td>1.140200</td>\n",
       "      <td>0.658295</td>\n",
       "      <td>1.786614</td>\n",
       "      <td>0.661971</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0.513078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.607209</td>\n",
       "      <td>0.706676</td>\n",
       "      <td>0.662904</td>\n",
       "      <td>1.818870</td>\n",
       "      <td>0.617975</td>\n",
       "      <td>3.318150</td>\n",
       "      <td>0.583932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.587561</td>\n",
       "      <td>1.869612</td>\n",
       "      <td>0.665526</td>\n",
       "      <td>1.812187</td>\n",
       "      <td>0.690894</td>\n",
       "      <td>0.607133</td>\n",
       "      <td>0.582607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.587746</td>\n",
       "      <td>1.428403</td>\n",
       "      <td>0.659129</td>\n",
       "      <td>1.827969</td>\n",
       "      <td>0.634447</td>\n",
       "      <td>-0.435978</td>\n",
       "      <td>0.525331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  1.575081  1.051777  0.654957  1.852348  0.661859 -0.058174  0.547797\n",
       "1  1.587002  1.167132  0.662903  1.845025  0.640522 -1.246360  0.503668\n",
       "2  1.578516  1.140200  0.658295  1.786614  0.661971 -6.907755  0.513078\n",
       "3  1.607209  0.706676  0.662904  1.818870  0.617975  3.318150  0.583932\n",
       "4  1.587561  1.869612  0.665526  1.812187  0.690894  0.607133  0.582607\n",
       "5  1.587746  1.428403  0.659129  1.827969  0.634447 -0.435978  0.525331"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output = pd.DataFrame(scaler.inverse_transform(df_output))\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.57508068, 1.58700217, 1.57851621, 1.60720906, 1.58756091,\n",
       "       1.58774566])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_forecast = df_output.iloc[:,0].values\n",
    "y_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.05135894, 2.51810131, 2.07247393, 2.01343609, 0.23437483,\n",
       "       1.86092044])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_validation_sv[country].iloc[:,0].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
